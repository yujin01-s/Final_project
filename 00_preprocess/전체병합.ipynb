{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524bb1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ íšŒì›ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: íšŒì›ì •ë³´ â†’ shape: (600000, 77)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: íšŒì›ì •ë³´_test.parquet\n",
      "ğŸ“‚ ì‹ ìš©ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì‹ ìš©ì •ë³´ â†’ shape: (600000, 42)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì‹ ìš©ì •ë³´_test.parquet\n",
      "ğŸ“‚ ìŠ¹ì¸ë§¤ì¶œì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ìŠ¹ì¸ë§¤ì¶œì •ë³´ â†’ shape: (600000, 406)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ìŠ¹ì¸ë§¤ì¶œì •ë³´_test.parquet\n",
      "ğŸ“‚ ì²­êµ¬ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì²­êµ¬ì •ë³´ â†’ shape: (600000, 46)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì²­êµ¬ì •ë³´_test.parquet\n",
      "ğŸ“‚ ì”ì•¡ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì”ì•¡ì •ë³´ â†’ shape: (600000, 82)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì”ì•¡ì •ë³´_test.parquet\n",
      "ğŸ“‚ ì±„ë„ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì±„ë„ì •ë³´ â†’ shape: (600000, 105)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì±„ë„ì •ë³´_test.parquet\n",
      "ğŸ“‚ ë§ˆì¼€íŒ…ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ë§ˆì¼€íŒ…ì •ë³´ â†’ shape: (600000, 64)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ë§ˆì¼€íŒ…ì •ë³´_test.parquet\n",
      "ğŸ“‚ ì„±ê³¼ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì„±ê³¼ì •ë³´ â†’ shape: (600000, 49)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì„±ê³¼ì •ë³´_test.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1~8 í´ë”ëª…ê³¼ ì €ì¥ìš© ì´ë¦„ ë§¤í•‘\n",
    "folder_map = {\n",
    "    \"1.íšŒì›ì •ë³´\": \"íšŒì›ì •ë³´\",\n",
    "    \"2.ì‹ ìš©ì •ë³´\": \"ì‹ ìš©ì •ë³´\",\n",
    "    \"3.ìŠ¹ì¸ë§¤ì¶œì •ë³´\": \"ìŠ¹ì¸ë§¤ì¶œì •ë³´\",\n",
    "    \"4.ì²­êµ¬ì…ê¸ˆì •ë³´\": \"ì²­êµ¬ì •ë³´\",\n",
    "    \"5.ì”ì•¡ì •ë³´\": \"ì”ì•¡ì •ë³´\",\n",
    "    \"6.ì±„ë„ì •ë³´\": \"ì±„ë„ì •ë³´\",\n",
    "    \"7.ë§ˆì¼€íŒ…ì •ë³´\": \"ë§ˆì¼€íŒ…ì •ë³´\", \n",
    "    \"8.ì„±ê³¼ì •ë³´\": \"ì„±ê³¼ì •ë³´\"\n",
    "}\n",
    "\n",
    "base_dir = \"../data/train/\"  # ê°ì ìƒí™©ì— ë§ê²Œ ìˆ˜ì •\n",
    "\n",
    "# ë°˜ë³µì ìœ¼ë¡œ ëª¨ë“  ë°ì´í„°ì…‹ ì²˜ë¦¬\n",
    "for folder, name in folder_map.items():\n",
    "    path = os.path.join(base_dir, folder, \"*.parquet\")\n",
    "    file_paths = sorted(glob.glob(path))\n",
    "    \n",
    "    if not file_paths:\n",
    "        print(f\"âŒ {name}: í•´ë‹¹ í´ë”ì— íŒŒì¼ ì—†ìŒ â†’ {path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"ğŸ“‚ {name} íŒŒì¼ ìˆ˜: {len(file_paths)}ê°œ\")\n",
    "\n",
    "    try:\n",
    "        df_list = [pd.read_parquet(fp) for fp in file_paths]\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "        \n",
    "        print(f\"âœ… ë³‘í•© ì™„ë£Œ: {name} â†’ shape: {merged_df.shape}\")\n",
    "        \n",
    "        # ì €ì¥\n",
    "        merged_df.to_parquet(f\"{name}_train.parquet\", index=False)\n",
    "        print(f\"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {name}_train.parquet\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"â— ì˜¤ë¥˜ ë°œìƒ: {name} â†’ {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff88485c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê¸°ì¤€: íšŒì›ì •ë³´ loaded (600000, 77)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì‹ ìš©ì •ë³´_test.parquet â†’ shape: (600000, 117)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ìŠ¹ì¸ë§¤ì¶œì •ë³´_test.parquet â†’ shape: (600000, 521)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì²­êµ¬ì •ë³´_test.parquet â†’ shape: (600000, 565)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì”ì•¡ì •ë³´_test.parquet â†’ shape: (600000, 645)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì±„ë„ì •ë³´_test.parquet â†’ shape: (600000, 748)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ë§ˆì¼€íŒ…ì •ë³´_test.parquet â†’ shape: (600000, 810)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì„±ê³¼ì •ë³´_test.parquet â†’ shape: (600000, 857)\n",
      "\n",
      "âœ… ìµœì¢… í†µí•© ì €ì¥ ì™„ë£Œ: í†µí•©_test_ë°ì´í„°.parquet\n",
      "ğŸ“Š ìµœì¢… shape: (600000, 857)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ê¸°ì¤€ íŒŒì¼: íšŒì›ì •ë³´\n",
    "merged = pd.read_parquet(\"íšŒì›ì •ë³´_train.parquet\")\n",
    "print(\"âœ… ê¸°ì¤€: íšŒì›ì •ë³´ loaded\", merged.shape)\n",
    "\n",
    "# ê¸°ì¤€ë…„ì›” ìƒì„±\n",
    "if 'ê¸°ì¤€ë…„ì›”' not in merged.columns:\n",
    "    if 'ê¸°ì¤€ì¼ì' in merged.columns:\n",
    "        merged['ê¸°ì¤€ë…„ì›”'] = merged['ê¸°ì¤€ì¼ì'].astype(str).str[:6]\n",
    "        print(\"ğŸ›  ê¸°ì¤€ í…Œì´ë¸”: ê¸°ì¤€ë…„ì›” íŒŒìƒ ì™„ë£Œ\")\n",
    "    else:\n",
    "        raise KeyError(\"â— ê¸°ì¤€ í…Œì´ë¸”ì— 'ê¸°ì¤€ë…„ì›”' ë˜ëŠ” 'ê¸°ì¤€ì¼ì' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë³‘í•©í•  ë‹¤ë¥¸ íŒŒì¼ ëª©ë¡\n",
    "other_files = [\n",
    "    \"ì‹ ìš©ì •ë³´_train.parquet\",\n",
    "    \"ìŠ¹ì¸ë§¤ì¶œì •ë³´_train.parquet\",\n",
    "    \"ì²­êµ¬ì •ë³´_train.parquet\",\n",
    "    \"ì”ì•¡ì •ë³´_train.parquet\",\n",
    "    \"ì±„ë„ì •ë³´_train.parquet\",\n",
    "    \"ë§ˆì¼€íŒ…ì •ë³´_train.parquet\",\n",
    "    \"ì„±ê³¼ì •ë³´_train.parquet\"\n",
    "]\n",
    "\n",
    "for file in other_files:\n",
    "    if os.path.exists(file):\n",
    "        temp = pd.read_parquet(file)\n",
    "\n",
    "        # ê¸°ì¤€ë…„ì›” ìƒì„±\n",
    "        if 'ê¸°ì¤€ë…„ì›”' not in temp.columns:\n",
    "            if 'ê¸°ì¤€ì¼ì' in temp.columns:\n",
    "                temp['ê¸°ì¤€ë…„ì›”'] = temp['ê¸°ì¤€ì¼ì'].astype(str).str[:6]\n",
    "                print(f\"ğŸ›  {file}: ê¸°ì¤€ë…„ì›” íŒŒìƒ ì™„ë£Œ\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ {file}: ê¸°ì¤€ë…„ì›” ìƒì„± ë¶ˆê°€ â†’ ë³‘í•© ê±´ë„ˆëœ€\")\n",
    "                continue\n",
    "\n",
    "        # ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° (ID, ê¸°ì¤€ë…„ì›” ì œì™¸)\n",
    "        overlap_cols = [col for col in temp.columns if col in merged.columns and col not in ['ID', 'ê¸°ì¤€ë…„ì›”']]\n",
    "        if overlap_cols:\n",
    "            print(f\"âš ï¸ ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° ({file}):\", overlap_cols)\n",
    "            temp = temp.drop(columns=overlap_cols)\n",
    "\n",
    "        merged = merged.merge(temp, on=['ID', 'ê¸°ì¤€ë…„ì›”'], how='left')\n",
    "        print(f\"ğŸ”— ë³‘í•© ì™„ë£Œ: {file} â†’ shape: {merged.shape}\")\n",
    "    else:\n",
    "        print(f\"âŒ íŒŒì¼ ì—†ìŒ: {file}\")\n",
    "\n",
    "# ì €ì¥\n",
    "merged.to_parquet(\"í†µí•©_train_ë°ì´í„°.parquet\", index=False)\n",
    "print(\"\\nâœ… ìµœì¢… í†µí•© ì €ì¥ ì™„ë£Œ: í†µí•©_train_ë°ì´í„°.parquet\")\n",
    "print(\"ğŸ“Š ìµœì¢… shape:\", merged.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef09848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ íšŒì›ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: íšŒì›ì •ë³´ â†’ shape: (2400000, 78)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: íšŒì›ì •ë³´_train.parquet\n",
      "ğŸ“‚ ì‹ ìš©ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì‹ ìš©ì •ë³´ â†’ shape: (2400000, 42)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì‹ ìš©ì •ë³´_train.parquet\n",
      "ğŸ“‚ ìŠ¹ì¸ë§¤ì¶œì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ìŠ¹ì¸ë§¤ì¶œì •ë³´ â†’ shape: (2400000, 406)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ìŠ¹ì¸ë§¤ì¶œì •ë³´_train.parquet\n",
      "ğŸ“‚ ì²­êµ¬ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì²­êµ¬ì •ë³´ â†’ shape: (2400000, 46)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì²­êµ¬ì •ë³´_train.parquet\n",
      "ğŸ“‚ ì”ì•¡ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì”ì•¡ì •ë³´ â†’ shape: (2400000, 82)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì”ì•¡ì •ë³´_train.parquet\n",
      "ğŸ“‚ ì±„ë„ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì±„ë„ì •ë³´ â†’ shape: (2400000, 105)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì±„ë„ì •ë³´_train.parquet\n",
      "ğŸ“‚ ë§ˆì¼€íŒ…ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ë§ˆì¼€íŒ…ì •ë³´ â†’ shape: (2400000, 64)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ë§ˆì¼€íŒ…ì •ë³´_train.parquet\n",
      "ğŸ“‚ ì„±ê³¼ì •ë³´ íŒŒì¼ ìˆ˜: 6ê°œ\n",
      "âœ… ë³‘í•© ì™„ë£Œ: ì„±ê³¼ì •ë³´ â†’ shape: (2400000, 49)\n",
      "ğŸ’¾ ì €ì¥ ì™„ë£Œ: ì„±ê³¼ì •ë³´_train.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# 1~8 í´ë”ëª…ê³¼ ì €ì¥ìš© ì´ë¦„ ë§¤í•‘\n",
    "folder_map = {\n",
    "    \"1.íšŒì›ì •ë³´\": \"íšŒì›ì •ë³´\",\n",
    "    \"2.ì‹ ìš©ì •ë³´\": \"ì‹ ìš©ì •ë³´\",\n",
    "    \"3.ìŠ¹ì¸ë§¤ì¶œì •ë³´\": \"ìŠ¹ì¸ë§¤ì¶œì •ë³´\",\n",
    "    \"4.ì²­êµ¬ì…ê¸ˆì •ë³´\": \"ì²­êµ¬ì •ë³´\",\n",
    "    \"5.ì”ì•¡ì •ë³´\": \"ì”ì•¡ì •ë³´\",\n",
    "    \"6.ì±„ë„ì •ë³´\": \"ì±„ë„ì •ë³´\",\n",
    "    \"7.ë§ˆì¼€íŒ…ì •ë³´\": \"ë§ˆì¼€íŒ…ì •ë³´\", \n",
    "    \"8.ì„±ê³¼ì •ë³´\": \"ì„±ê³¼ì •ë³´\"\n",
    "}\n",
    "\n",
    "base_dir = \"../data/train/\"  # ê°ì ìƒí™©ì— ë§ê²Œ ìˆ˜ì •\n",
    "\n",
    "# ë°˜ë³µì ìœ¼ë¡œ ëª¨ë“  ë°ì´í„°ì…‹ ì²˜ë¦¬\n",
    "for folder, name in folder_map.items():\n",
    "    path = os.path.join(base_dir, folder, \"*.parquet\")\n",
    "    file_paths = sorted(glob.glob(path))\n",
    "    \n",
    "    if not file_paths:\n",
    "        print(f\"âŒ {name}: í•´ë‹¹ í´ë”ì— íŒŒì¼ ì—†ìŒ â†’ {path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"ğŸ“‚ {name} íŒŒì¼ ìˆ˜: {len(file_paths)}ê°œ\")\n",
    "\n",
    "    try:\n",
    "        df_list = [pd.read_parquet(fp) for fp in file_paths]\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "        \n",
    "        print(f\"âœ… ë³‘í•© ì™„ë£Œ: {name} â†’ shape: {merged_df.shape}\")\n",
    "        \n",
    "        # ì €ì¥\n",
    "        merged_df.to_parquet(f\"{name}_train.parquet\", index=False)\n",
    "        print(f\"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {name}_train.parquet\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"â— ì˜¤ë¥˜ ë°œìƒ: {name} â†’ {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "592b1106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê¸°ì¤€: íšŒì›ì •ë³´ loaded (2400000, 78)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì‹ ìš©ì •ë³´_train.parquet â†’ shape: (2400000, 118)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ìŠ¹ì¸ë§¤ì¶œì •ë³´_train.parquet â†’ shape: (2400000, 522)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì²­êµ¬ì •ë³´_train.parquet â†’ shape: (2400000, 566)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì”ì•¡ì •ë³´_train.parquet â†’ shape: (2400000, 646)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì±„ë„ì •ë³´_train.parquet â†’ shape: (2400000, 749)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ë§ˆì¼€íŒ…ì •ë³´_train.parquet â†’ shape: (2400000, 811)\n",
      "ğŸ”— ë³‘í•© ì™„ë£Œ: ì„±ê³¼ì •ë³´_train.parquet â†’ shape: (2400000, 858)\n",
      "\n",
      "âœ… ìµœì¢… í†µí•© ì €ì¥ ì™„ë£Œ: í†µí•©_train_ë°ì´í„°.parquet\n",
      "ğŸ“Š ìµœì¢… shape: (2400000, 858)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ê¸°ì¤€ íŒŒì¼: íšŒì›ì •ë³´\n",
    "merged = pd.read_parquet(\"íšŒì›ì •ë³´_train.parquet\")\n",
    "print(\"âœ… ê¸°ì¤€: íšŒì›ì •ë³´ loaded\", merged.shape)\n",
    "\n",
    "# ê¸°ì¤€ë…„ì›” ìƒì„±\n",
    "if 'ê¸°ì¤€ë…„ì›”' not in merged.columns:\n",
    "    if 'ê¸°ì¤€ì¼ì' in merged.columns:\n",
    "        merged['ê¸°ì¤€ë…„ì›”'] = merged['ê¸°ì¤€ì¼ì'].astype(str).str[:6]\n",
    "        print(\"ğŸ›  ê¸°ì¤€ í…Œì´ë¸”: ê¸°ì¤€ë…„ì›” íŒŒìƒ ì™„ë£Œ\")\n",
    "    else:\n",
    "        raise KeyError(\"â— ê¸°ì¤€ í…Œì´ë¸”ì— 'ê¸°ì¤€ë…„ì›”' ë˜ëŠ” 'ê¸°ì¤€ì¼ì' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë³‘í•©í•  ë‹¤ë¥¸ íŒŒì¼ ëª©ë¡\n",
    "other_files = [\n",
    "    \"ì‹ ìš©ì •ë³´_train.parquet\",\n",
    "    \"ìŠ¹ì¸ë§¤ì¶œì •ë³´_train.parquet\",\n",
    "    \"ì²­êµ¬ì •ë³´_train.parquet\",\n",
    "    \"ì”ì•¡ì •ë³´_train.parquet\",\n",
    "    \"ì±„ë„ì •ë³´_train.parquet\",\n",
    "    \"ë§ˆì¼€íŒ…ì •ë³´_train.parquet\",\n",
    "    \"ì„±ê³¼ì •ë³´_train.parquet\"\n",
    "]\n",
    "\n",
    "for file in other_files:\n",
    "    if os.path.exists(file):\n",
    "        temp = pd.read_parquet(file)\n",
    "\n",
    "        # ê¸°ì¤€ë…„ì›” ìƒì„±\n",
    "        if 'ê¸°ì¤€ë…„ì›”' not in temp.columns:\n",
    "            if 'ê¸°ì¤€ì¼ì' in temp.columns:\n",
    "                temp['ê¸°ì¤€ë…„ì›”'] = temp['ê¸°ì¤€ì¼ì'].astype(str).str[:6]\n",
    "                print(f\"ğŸ›  {file}: ê¸°ì¤€ë…„ì›” íŒŒìƒ ì™„ë£Œ\")\n",
    "            else:\n",
    "                print(f\"âš ï¸ {file}: ê¸°ì¤€ë…„ì›” ìƒì„± ë¶ˆê°€ â†’ ë³‘í•© ê±´ë„ˆëœ€\")\n",
    "                continue\n",
    "\n",
    "        # ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° (ID, ê¸°ì¤€ë…„ì›” ì œì™¸)\n",
    "        overlap_cols = [col for col in temp.columns if col in merged.columns and col not in ['ID', 'ê¸°ì¤€ë…„ì›”']]\n",
    "        if overlap_cols:\n",
    "            print(f\"âš ï¸ ì¤‘ë³µ ì»¬ëŸ¼ ì œê±° ({file}):\", overlap_cols)\n",
    "            temp = temp.drop(columns=overlap_cols)\n",
    "\n",
    "        merged = merged.merge(temp, on=['ID', 'ê¸°ì¤€ë…„ì›”'], how='left')\n",
    "        print(f\"ğŸ”— ë³‘í•© ì™„ë£Œ: {file} â†’ shape: {merged.shape}\")\n",
    "    else:\n",
    "        print(f\"âŒ íŒŒì¼ ì—†ìŒ: {file}\")\n",
    "\n",
    "# ì €ì¥\n",
    "merged.to_parquet(\"í†µí•©_train_ë°ì´í„°.parquet\", index=False)\n",
    "print(\"\\nâœ… ìµœì¢… í†µí•© ì €ì¥ ì™„ë£Œ: í†µí•©_train_ë°ì´í„°.parquet\")\n",
    "print(\"ğŸ“Š ìµœì¢… shape:\", merged.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
