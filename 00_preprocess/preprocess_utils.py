import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
from statsmodels.stats.outliers_influence import variance_inflation_factor

# segment_target ì˜ˆì‹œ: ["C", "D"], ["A", "B"], ["E", "A", "B", "C", "D"]
def prepare_data(df, segment_target):
    X_all = df[df['Segment'].isin(segment_target)].copy()
    y_all = LabelEncoder().fit_transform(X_all['Segment'])
    return train_test_split(X_all, y_all, test_size=0.2, stratify=y_all, random_state=42)
    """
    # 1ë‹¨ê³„: E vs ë‚˜ë¨¸ì§€
    X_train, X_val, y_train, y_val = prepare_data(df, ['E', 'A', 'B', 'C', 'D'])

    # 2ë‹¨ê³„: AB vs CD
    X_train, X_val, y_train, y_val = prepare_data(df, ['A', 'B', 'C', 'D'])

    # 3ë‹¨ê³„: A vs B
    X_train, X_val, y_train, y_val = prepare_data(df, ['A', 'B'])

    # 4ë‹¨ê³„: C vs D
    X_train, X_val, y_train, y_val = prepare_data(df, ['C', 'D'])
    """

# ë°ì´í„° ì¤€ë¹„ (íŒŒìƒë³€ìˆ˜ ìƒì„±)
def data_derive(df, stage='cd'):
    df = df.copy()

    # íŒŒìƒë³€ìˆ˜ ìë™ ìƒì„±ë§Œ ìˆ˜í–‰
    if stage == 'cd':
        df = generate_cd_derived_features(df)
    # elif stage == 'ab':
    #     df = generate_ab_derived_features(df)
    # elif stage == 'e':
    #     df = generate_e_derived_features(df)

    return df

# VIF ê¸°ë°˜ í”¼ì²˜ ì œê±°
def remove_high_vif(df, features, fixed=[], threshold=10.0):
    features = features.copy()
    while True:
        X = df[features].fillna(0)
        vif = pd.Series(
            [variance_inflation_factor(X.values, i) for i in range(X.shape[1])],
            index=X.columns
        )
        max_vif = vif.drop(labels=fixed).max()
        if max_vif > threshold:
            to_remove = vif.drop(labels=fixed).idxmax()
            features.remove(to_remove)
        else:
            break
    return features

# ì˜ˆì¸¡ í™•ë¥  ìƒì„± í•¨ìˆ˜
def predict_proba_on_fixed_val(X_train, y_train, X_val, features):
    sm = SMOTE(random_state=42)
    X_train_res, y_train_res = sm.fit_resample(X_train[features], y_train)
    model = XGBClassifier(n_estimators=300, max_depth=4, learning_rate=0.1, random_state=42)
    model.fit(X_train_res, y_train_res)
    return model.predict_proba(X_val[features])[:, 1]

# íŒŒìƒë³€ìˆ˜ ìƒì„±
def safe_div(a, b):
    return np.where(b == 0, 0, a / b)

# ë¼ë²¨ì¸ì½”ë”©
def encode_categorical_columns(df):
    cat_cols = df.select_dtypes(include='object').columns.tolist()
    for col in cat_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))
        print(f"ğŸ”µ {col} ì¸ì½”ë”© ì™„ë£Œ")
    return df

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (í‰ê· )
def impute_missing_values(df, strategy='mean'):
    imputer = SimpleImputer(strategy=strategy)
    df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)
    print(f"âœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ (strategy={strategy})")
    return df_imputed

# ë²”ì£¼í™” ì „ì²˜ë¦¬
def map_categorical_columns(df, verbose=True):
    """
    ë¯¸ë¦¬ ì •ì˜ëœ ë§¤í•‘ ê¸°ì¤€ì— ë”°ë¼ ë²”ì£¼í˜• ì»¬ëŸ¼ë“¤ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì²˜ë¦¬ ì»¬ëŸ¼: ê±°ì£¼ì‹œë„ëª…, ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M, í•œë„ì¦ì•¡íšŸìˆ˜_R12M, ì´ìš©ê¸ˆì•¡ëŒ€,
              í• ì¸ê±´ìˆ˜_R3M, í• ì¸ê±´ìˆ˜_B0M, ë°©ë¬¸íšŸìˆ˜_PC_R6M, ë°©ë¬¸íšŸìˆ˜_ì•±_R6M, ë°©ë¬¸ì¼ìˆ˜_PC_R6M
    """

    # 1. ê±°ì£¼ì‹œë„ëª… â†’ ìˆ˜ë„ê¶Œ ì—¬ë¶€
    capital_area = ['ì„œìš¸', 'ê²½ê¸°', 'ì¸ì²œ']
    if 'ê±°ì£¼ì‹œë„ëª…' in df.columns:
        df['ê±°ì£¼ì‹œë„ëª…'] = df['ê±°ì£¼ì‹œë„ëª…'].apply(lambda x: 1 if x in capital_area else 0)

    # 2. ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M
    mapping = {"0ê°œ": 0, "1ê°œì´ìƒ": 1}
    if 'ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M' in df.columns:
        df['ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M'] = df['ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M'].map(mapping).astype(int)
        if verbose: print("[ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M] ì¸ì½”ë”© ì™„ë£Œ")

    # 3. í•œë„ì¦ì•¡íšŸìˆ˜_R12M
    mapping = {"0íšŒ": 0, "1íšŒì´ìƒ": 1}
    if 'í•œë„ì¦ì•¡íšŸìˆ˜_R12M' in df.columns:
        df['í•œë„ì¦ì•¡íšŸìˆ˜_R12M'] = df['í•œë„ì¦ì•¡íšŸìˆ˜_R12M'].map(mapping).astype(int)
        if verbose: print("[í•œë„ì¦ì•¡íšŸìˆ˜_R12M] ì¸ì½”ë”© ì™„ë£Œ")

    # 4. ì´ìš©ê¸ˆì•¡ëŒ€ (ì¤‘ê°„ê°’ ê¸°ì¤€: ë§Œì› ë‹¨ìœ„)
    mapping = {
        "09.ë¯¸ì‚¬ìš©": 0,
        "05.10ë§Œì›-": 5,
        "04.10ë§Œì›+": 20,
        "03.30ë§Œì›+": 40,
        "02.50ë§Œì›+": 75,
        "01.100ë§Œì›+": 150
    }
    if 'ì´ìš©ê¸ˆì•¡ëŒ€' in df.columns:
        df['ì´ìš©ê¸ˆì•¡ëŒ€'] = df['ì´ìš©ê¸ˆì•¡ëŒ€'].map(mapping)
        if verbose: print("[ì´ìš©ê¸ˆì•¡ëŒ€] ì¤‘ê°„ê°’ ì¸ì½”ë”© ì™„ë£Œ")

   # 5. í• ì¸ê±´ìˆ˜ ì¸ì½”ë”©
    discount_map = {
        "1íšŒ ì´ìƒ": 1,
        "10íšŒ ì´ìƒ": 10,
        "20íšŒ ì´ìƒ": 20,
        "30íšŒ ì´ìƒ": 30,
        "40íšŒ ì´ìƒ": 40
    }
    for col in ['í• ì¸ê±´ìˆ˜_R3M', 'í• ì¸ê±´ìˆ˜_B0M']:
        if col in df.columns:
            df[col] = df[col].map(discount_map).astype(int)
            if verbose: print(f"[{col}] ì¸ì½”ë”© ì™„ë£Œ")

    # 6. ë°©ë¬¸íšŸìˆ˜ ë° ë°©ë¬¸ì¼ìˆ˜ ì¸ì½”ë”©
    visit_map = {
        "1íšŒ ì´ìƒ": 1,
        "10íšŒ ì´ìƒ": 10,
        "20íšŒ ì´ìƒ": 20,
        "30íšŒ ì´ìƒ": 30,
        "40íšŒ ì´ìƒ": 40,
        "50íšŒ ì´ìƒ": 50,
        "60íšŒ ì´ìƒ": 60,
        "70íšŒ ì´ìƒ": 70,
        "80íšŒ ì´ìƒ": 80
    }

    visit_cols = ['ë°©ë¬¸íšŸìˆ˜_PC_R6M', 'ë°©ë¬¸íšŸìˆ˜_ì•±_R6M', 'ë°©ë¬¸ì¼ìˆ˜_PC_R6M']
    for col in visit_cols:
        if col in df.columns:
            df[col] = df[col].map(visit_map).astype(int)
            if verbose: print(f"[{col}] ì¸ì½”ë”© ì™„ë£Œ")

    return df

# CD íŒŒìƒë³€ìˆ˜ ìƒì„±
def generate_cd_derived_features(df):
    df = df.copy()
    df['ì˜¤í”„ë¼ì¸_ì†Œë¹„ê¸‰ë“±ë¹„ìœ¨'] = safe_div(df['ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_B0M'], df['ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_R6M'] / 6)
    df['ì¼ì‹œë¶ˆ_ìµœê·¼ì„±ì§€í‘œ'] = safe_div(df['ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_B0M'], df['ìµœëŒ€ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M'] + 1)
    df['ì†Œë¹„_í‰ê· ëŒ€ìµœëŒ€ë¹„ìœ¨'] = safe_div((df['ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©'] + 1) / 3, df['ìµœëŒ€ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M'] + 1)
    df['ì²­êµ¬_ìµœê·¼ì„±ì§€í‘œ'] = safe_div(df['ì •ìƒì²­êµ¬ì›ê¸ˆ_B0M'], df['ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M'] + 1)
    df['ì†Œì§„ìœ¨_ì°¨ì´'] = df['ì”ì•¡_ì‹ íŒí‰ê· í•œë„ì†Œì§„ìœ¨_r6m'] - df['ì”ì•¡_ì‹ íŒcaí‰ê· í•œë„ì†Œì§„ìœ¨_r6m']
    df['ì¹´ë“œì§‘ì¤‘ë„'] = safe_div(df['_1ìˆœìœ„ì¹´ë“œì´ìš©ê¸ˆì•¡'], df['ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©'] + df['ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©ì²´í¬'] + 1)
    df['ì…ê¸ˆì²­êµ¬ë¹„ìœ¨'] = safe_div(df['ì •ìƒì…ê¸ˆì›ê¸ˆ_B5M'], df['ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M'] + 1)
    df['ì¼ì‹œë¶ˆ_ê¸ˆì•¡ë¹„ìœ¨'] = safe_div(df['ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_B0M'], df['í‰ì”_ì¼ì‹œë¶ˆ_6M'] + 1)
    df['í• ì¸ì „ì´ììœ¨_í‰ê· '] = (df['RVì¼ì‹œë¶ˆì´ììœ¨_í• ì¸ì „'] + df['CAì´ììœ¨_í• ì¸ì „']) / 2
    return df