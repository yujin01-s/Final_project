# %%
import pandas as pd

# íŒŒì¼ ê²½ë¡œ
file_path = "../../data/í†µí•©_train_ë°ì´í„°.parquet"
df = pd.read_parquet(file_path)

# %%
top_ab = ['í• ë¶€ê¸ˆì•¡_3M_R12M',
 'ì´ìš©ê¸ˆì•¡_í• ë¶€_ë¬´ì´ì_R12M',
 'ì´ìš©ê±´ìˆ˜_í• ë¶€_ë¬´ì´ì_R12M',
 'ì •ìƒì…ê¸ˆì›ê¸ˆ_B0M',
 'ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_R6M',
 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B0M',
 'ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_R3M',
 '_1ìˆœìœ„ì¹´ë“œì´ìš©ê¸ˆì•¡',
 'í‰ì”_ì¼ì‹œë¶ˆ_í•´ì™¸_6M',
 'ìŠ¹ì¸ê±°ì ˆê±´ìˆ˜_ì…ë ¥ì˜¤ë¥˜_R3M',
 'ì²­êµ¬ê¸ˆì•¡_R3M',
 'ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M',
 'ì´ìš©ê¸ˆì•¡_í• ë¶€_ë¬´ì´ì_R3M',
 'ì´ìš©ê¸ˆì•¡_í• ë¶€_ë¬´ì´ì_R6M',
 'ì •ìƒì…ê¸ˆì›ê¸ˆ_B5M',
 'ì´ìš©ê¸ˆì•¡_í• ë¶€_R12M',
 'ë§ˆì¼_ì ë¦½í¬ì¸íŠ¸_R3M',
 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B2M',
 'í¬ì¸íŠ¸_ë§ˆì¼ë¦¬ì§€_í™˜ì‚°_B0M',
 'ì²­êµ¬ê¸ˆì•¡_B0',
 'ì •ìƒì…ê¸ˆì›ê¸ˆ_B2M',
 'í• ë¶€ê±´ìˆ˜_ë¬´ì´ì_3M_R12M',
 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M',
 'ì²­êµ¬ê¸ˆì•¡_R6M',
 'ì—¬ìœ _ìˆ™ë°•ì´ìš©ê¸ˆì•¡',
 'ìµœëŒ€ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M',
 '_1ìˆœìœ„ì—…ì¢…_ì´ìš©ê¸ˆì•¡',
 'ì”ì•¡_í• ë¶€_B0M',
 'í• ë¶€ê¸ˆì•¡_ë¬´ì´ì_3M_R12M',
 'ì”ì•¡_í• ë¶€_ë¬´ì´ì_B0M']

# %%
top_cde = ['ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R3M',
 'ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©ì²´í¬',
 'ì •ìƒì…ê¸ˆì›ê¸ˆ_B0M',
 'ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_R6M',
 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B0M',
 'ì´ìš©ê±´ìˆ˜_ì‹ ìš©_R6M',
 'ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_R3M',
 'ì´ìš©ê±´ìˆ˜_ì¼ì‹œë¶ˆ_R12M',
 '_1ìˆœìœ„ì¹´ë“œì´ìš©ê¸ˆì•¡',
 'ì´ìš©ê¸ˆì•¡_ì˜¤í”„ë¼ì¸_B0M',
 'ì²­êµ¬ê¸ˆì•¡_R3M',
 'ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M',
 'ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©',
 'ì •ìƒì…ê¸ˆì›ê¸ˆ_B5M',
 'ì´ìš©ê±´ìˆ˜_ì˜¤í”„ë¼ì¸_B0M',
 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B2M',
 'ì´ìš©ê±´ìˆ˜_ì‹ íŒ_R12M',
 'ì²­êµ¬ê¸ˆì•¡_B0',
 'ì •ìƒì…ê¸ˆì›ê¸ˆ_B2M',
 'ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_B0M',
 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M',
 'ì²­êµ¬ê¸ˆì•¡_R6M',
 'ìµœëŒ€ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R12M',
 'ì´ìš©ê°€ë§¹ì ìˆ˜',
 'ì´ìš©ê±´ìˆ˜_ì‹ ìš©_R12M',
 'ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_R6M']

# %%
# ğŸ“Œ PC1~PC5ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ì¤‘ìš”í•œ ë³€ìˆ˜:
pca_cols = ['CAì´ììœ¨_í• ì¸ì „', 'CLì´ììœ¨_í• ì¸ì „', 'RV_í‰ê· ì”ì•¡_R3M', 'RVì¼ì‹œë¶ˆì´ììœ¨_í• ì¸ì „', 'RVìµœì†Œê²°ì œë¹„ìœ¨', 'RVí˜„ê¸ˆì„œë¹„ìŠ¤ì´ììœ¨_í• ì¸ì „', 'ë°©ë¬¸ì›”ìˆ˜_ì•±_R6M', 'ë°©ë¬¸ì¼ìˆ˜_ì•±_B0M', 'ë°©ë¬¸ì¼ìˆ˜_ì•±_R6M', 'ë°©ë¬¸íšŸìˆ˜_ì•±_B0M', 'ë°©ë¬¸í›„ê²½ê³¼ì›”_ì•±_R6M', 'ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©', 'ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©ì²´í¬', 'ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_B0M', 'ì´ìš©ê¸ˆì•¡ëŒ€', 'ì¼ì‹œë¶ˆONLYì „í™˜ê°€ëŠ¥ì—¬ë¶€', 'ì”ì•¡_ë¦¬ë³¼ë¹™ì¼ì‹œë¶ˆì´ì›”_B0M', 'ì”ì•¡_ì¼ì‹œë¶ˆ_B0M', 'ì”ì•¡_ì¼ì‹œë¶ˆ_B1M', 'ì”ì•¡_ì¼ì‹œë¶ˆ_B2M', 'ì”ì•¡_ì¹´ë“œë¡ _B0M', 'ì”ì•¡_ì¹´ë“œë¡ _B1M', 'ì”ì•¡_ì¹´ë“œë¡ _B2M', 'ì”ì•¡_ì¹´ë“œë¡ _B3M', 'ì”ì•¡_ì¹´ë“œë¡ _B4M', 'ì”ì•¡_ì¹´ë“œë¡ _B5M', 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B0M', 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B2M', 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M', 'ì²­êµ¬ê¸ˆì•¡_B0', 'ì²­êµ¬ê¸ˆì•¡_R3M', 'ì²­êµ¬ê¸ˆì•¡_R6M', 'ìµœì¢…ì¹´ë“œë¡ _ëŒ€ì¶œê¸ˆì•¡', 'ì¹´ë“œë¡ ì´ìš©ê¸ˆì•¡_ëˆ„ì ', 'í‰ì”_RVì¼ì‹œë¶ˆ_3M', 'í‰ì”_RVì¼ì‹œë¶ˆ_6M', 'í‰ì”_ì¼ì‹œë¶ˆ_3M', 'í‰ì”_ì¼ì‹œë¶ˆ_6M', 'í‰ì”_ì¹´ë“œë¡ _3M', 'í‰ì”_ì¹´ë“œë¡ _6M', 'í‰ì”_í• ë¶€_3M', 'í™ˆí˜ì´ì§€_ê¸ˆìœµê±´ìˆ˜_R3M', 'í™ˆí˜ì´ì§€_ê¸ˆìœµê±´ìˆ˜_R6M', 'í™ˆí˜ì´ì§€_ì„ ê²°ì œê±´ìˆ˜_R3M', 'í™ˆí˜ì´ì§€_ì„ ê²°ì œê±´ìˆ˜_R6M']

# %%
selected_cols=(top_ab + top_cde + pca_cols)
selected_cols = list(dict.fromkeys(selected_cols))

# %%
def map_categorical_columns(df, verbose=True):
    """
    ë¯¸ë¦¬ ì •ì˜ëœ ë§¤í•‘ ê¸°ì¤€ì— ë”°ë¼ ë²”ì£¼í˜• ì»¬ëŸ¼ë“¤ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ì²˜ë¦¬ ì»¬ëŸ¼: ê±°ì£¼ì‹œë„ëª…, ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M, í•œë„ì¦ì•¡íšŸìˆ˜_R12M, ì´ìš©ê¸ˆì•¡ëŒ€,
              í• ì¸ê±´ìˆ˜_R3M, í• ì¸ê±´ìˆ˜_B0M, ë°©ë¬¸íšŸìˆ˜_PC_R6M, ë°©ë¬¸íšŸìˆ˜_ì•±_R6M, ë°©ë¬¸ì¼ìˆ˜_PC_R6M
    """

    # 1. ê±°ì£¼ì‹œë„ëª… â†’ ìˆ˜ë„ê¶Œ ì—¬ë¶€
    capital_area = ['ì„œìš¸', 'ê²½ê¸°', 'ì¸ì²œ']
    if 'ê±°ì£¼ì‹œë„ëª…' in df.columns:
        df['ê±°ì£¼ì‹œë„ëª…'] = df['ê±°ì£¼ì‹œë„ëª…'].apply(lambda x: 1 if x in capital_area else 0)

    # 2. ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M
    mapping = {"0ê°œ": 0, "1ê°œì´ìƒ": 1}
    if 'ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M' in df.columns:
        df['ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M'] = df['ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M'].map(mapping).astype(int)
        if verbose: print("[ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M] ì¸ì½”ë”© ì™„ë£Œ")

    # 3. í•œë„ì¦ì•¡íšŸìˆ˜_R12M
    mapping = {"0íšŒ": 0, "1íšŒì´ìƒ": 1}
    if 'í•œë„ì¦ì•¡íšŸìˆ˜_R12M' in df.columns:
        df['í•œë„ì¦ì•¡íšŸìˆ˜_R12M'] = df['í•œë„ì¦ì•¡íšŸìˆ˜_R12M'].map(mapping).astype(int)
        if verbose: print("[í•œë„ì¦ì•¡íšŸìˆ˜_R12M] ì¸ì½”ë”© ì™„ë£Œ")

    # 4. ì´ìš©ê¸ˆì•¡ëŒ€ (ì¤‘ê°„ê°’ ê¸°ì¤€: ë§Œì› ë‹¨ìœ„)
    mapping = {
        "09.ë¯¸ì‚¬ìš©": 0,
        "05.10ë§Œì›-": 5,
        "04.10ë§Œì›+": 20,
        "03.30ë§Œì›+": 40,
        "02.50ë§Œì›+": 75,
        "01.100ë§Œì›+": 150
    }
    if 'ì´ìš©ê¸ˆì•¡ëŒ€' in df.columns:
        df['ì´ìš©ê¸ˆì•¡ëŒ€'] = df['ì´ìš©ê¸ˆì•¡ëŒ€'].map(mapping)
        if verbose: print("[ì´ìš©ê¸ˆì•¡ëŒ€] ì¤‘ê°„ê°’ ì¸ì½”ë”© ì™„ë£Œ")

   # 5. í• ì¸ê±´ìˆ˜ ì¸ì½”ë”©
    discount_map = {
        "1íšŒ ì´ìƒ": 1,
        "10íšŒ ì´ìƒ": 10,
        "20íšŒ ì´ìƒ": 20,
        "30íšŒ ì´ìƒ": 30,
        "40íšŒ ì´ìƒ": 40
    }
    for col in ['í• ì¸ê±´ìˆ˜_R3M', 'í• ì¸ê±´ìˆ˜_B0M']:
        if col in df.columns:
            df[col] = df[col].map(discount_map).astype(int)
            if verbose: print(f"[{col}] ì¸ì½”ë”© ì™„ë£Œ")

    # 6. ë°©ë¬¸íšŸìˆ˜ ë° ë°©ë¬¸ì¼ìˆ˜ ì¸ì½”ë”©
    visit_map = {
        "1íšŒ ì´ìƒ": 1,
        "10íšŒ ì´ìƒ": 10,
        "20íšŒ ì´ìƒ": 20,
        "30íšŒ ì´ìƒ": 30,
        "40íšŒ ì´ìƒ": 40,
        "50íšŒ ì´ìƒ": 50,
        "60íšŒ ì´ìƒ": 60,
        "70íšŒ ì´ìƒ": 70,
        "80íšŒ ì´ìƒ": 80
    }

    visit_cols = ['ë°©ë¬¸íšŸìˆ˜_PC_R6M', 'ë°©ë¬¸íšŸìˆ˜_ì•±_R6M', 'ë°©ë¬¸ì¼ìˆ˜_PC_R6M']
    for col in visit_cols:
        if col in df.columns:
            df[col] = df[col].map(visit_map).astype(int)
            if verbose: print(f"[{col}] ì¸ì½”ë”© ì™„ë£Œ")

    return df

# %%
df = map_categorical_columns(df)

# %%
ab_cols=(top_ab + pca_cols)
ab_cols = list(dict.fromkeys(ab_cols))

# %%
# ğŸ“Œ Segment ë¼ë²¨ ê¸°ì¤€: A/B â†’ 1, C/D/E â†’ 0
df['is_ab'] = df['Segment'].map(lambda x: 1 if x in ['A', 'B'] else 0)

# ğŸ‘‡ ì˜ˆì‹œìš© í”¼ì²˜ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (ì‚¬ìš© ì¤‘ì¸ ê±¸ë¡œ ëŒ€ì²´í•˜ì„¸ìš”)
X = df[selected_cols]  # ì„ íƒëœ í”¼ì²˜ë“¤
y = df['is_ab']       # ì´ì§„ íƒ€ê²Ÿ

# âœ… Train / Validation ë¶„ë¦¬
from sklearn.model_selection import train_test_split
X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

# âœ… ëª¨ë¸ í›„ë³´ ì •ì˜
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, f1_score, confusion_matrix

models = {
#    "Logistic": LogisticRegression(max_iter=1000, class_weight='balanced'),
#    "RandomForest": RandomForestClassifier(n_estimators=100, class_weight='balanced'),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=(y == 0).sum() / (y == 1).sum()),
#    "LightGBM": LGBMClassifier(class_weight='balanced')
}

# âœ… ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ í‰ê°€
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_val)
    f1 = f1_score(y_val, preds)
    print(f"\nğŸ“Œ [{name}] F1-score: {f1:.4f}")
    print(classification_report(y_val, preds))
    print(confusion_matrix(y_val, preds))


# %%
# A/B ì¶”ë ¤ì§„ ë°ì´í„°ì—ì„œ
ab_df = df[df['is_ab'] == 1].copy()

# íƒ€ê²Ÿ: A=0, B=1
y_ab = ab_df['Segment'].map({'A': 0, 'B': 1})

# ì „ì²´ í”¼ì²˜ì…‹
X_ab_all = ab_df[ab_cols]

# %%
from xgboost import XGBClassifier
import pandas as pd

# ê°„ë‹¨í•œ XGBoost ëª¨ë¸ í•™ìŠµ
xgb_ab = XGBClassifier()
xgb_ab.fit(X_ab_all, y_ab)

# ì¤‘ìš”ë„ ì¶”ì¶œ
importances = pd.Series(xgb_ab.feature_importances_, index=X_ab_all.columns)
top_features_ab = importances.sort_values(ascending=False).head(20).index.tolist()

print("ğŸ“Œ A/Bì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í”¼ì²˜ Top 20:")
print(top_features_ab)

# %%
# ì„ íƒëœ í”¼ì²˜ë§Œ ì‚¬ìš©
X_ab = X_ab_all[top_features_ab]

# %%
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

X_train_ab, X_val_ab, y_train_ab, y_val_ab = train_test_split(X_ab, y_ab, stratify=y_ab, test_size=0.2, random_state=42)

model_ab_final = XGBClassifier()
model_ab_final.fit(X_train_ab, y_train_ab)
preds_ab = model_ab_final.predict(X_val_ab)

print(classification_report(y_val_ab, preds_ab))

# %%
# ab_dfë¥¼ X_abì™€ ê°™ì€ ì¸ë±ìŠ¤ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
ab_df = ab_df.loc[X_ab.index].copy()

# ì˜ˆì¸¡ê°’ ì €ì¥
ab_preds = model_ab_final.predict(X_ab)
ab_df['Segment_pred'] = ab_preds
ab_df['Segment_pred'] = ab_df['Segment_pred'].map({0: 'A', 1: 'B'})


# %%
cde_cols=(top_cde + pca_cols)
cde_cols = list(dict.fromkeys(cde_cols))

# %%
cols_needed = cde_cols + ['Segment', 'ID']
cde_df = df.loc[df['is_ab'] == 0, cols_needed]


# %%
# íƒ€ê²Ÿ: Segment ë¬¸ì â†’ ìˆ«ì ë¼ë²¨
y_cde = cde_df['Segment'].map({'C': 0, 'D': 1, 'E': 2})

# ì…ë ¥ í”¼ì²˜
X_cde = cde_df[cde_cols]

# %%
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from xgboost import XGBClassifier

# í•™ìŠµìš© ë°ì´í„° ë¶„ë¦¬
X_train_cde, X_val_cde, y_train_cde, y_val_cde = train_test_split(
    X_cde, y_cde, stratify=y_cde, test_size=0.2, random_state=42
)

# ë‹¤ì¤‘ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ
model_cde = XGBClassifier(objective='multi:softmax', num_class=3, eval_metric='mlogloss')
model_cde.fit(X_train_cde, y_train_cde)

# ì˜ˆì¸¡ ë° í‰ê°€
preds_cde = model_cde.predict(X_val_cde)
print(classification_report(y_val_cde, preds_cde))

# %%
# ì „ì²´ ì˜ˆì¸¡ (í•™ìŠµìš© ë°ì´í„° ì „ì²´ë¡œ)
cde_preds = model_cde.predict(X_cde)

# ìˆ«ì â†’ ë¬¸ì ë¼ë²¨ ë³µì›
cde_df['Segment_pred'] = pd.Series(cde_preds, index=X_cde.index)
cde_df['Segment_pred'] = cde_df['Segment_pred'].map({0: 'C', 1: 'D', 2: 'E'})

# %%
# ab_dfëŠ” ì´ì „ì— Segment_predê°€ í¬í•¨ëœ A/B ì˜ˆì¸¡ ê²°ê³¼
final_df = pd.concat([ab_df, cde_df])

# ID ê¸°ì¤€ ì •ë ¬
final_df = final_df.sort_values('ID')

# ì œì¶œ íŒŒì¼ ìƒì„±
submission = final_df[['ID', 'Segment_pred']].rename(columns={'Segment_pred': 'Segment'})
submission.to_csv('final_submission.csv', index=False)

# %%
test_df = pd.read_parquet("../../data/í†µí•©_test_ë°ì´í„°.parquet")
X_test = test_df[selected_cols].copy()  # ë˜ëŠ” ab_cols, cde_cols ê¸°ë°˜

# ID ë°±ì—…
test_ids = test_df['ID']

# %%
from sklearn.preprocessing import LabelEncoder

# test_dfì— ë²”ì£¼í˜• ì»¬ëŸ¼ ë³€í™˜ ì ìš©
test_df = map_categorical_columns(test_df)
test_df.update(test_df)  # ì¸ì½”ë”©ëœ ì»¬ëŸ¼ë§Œ ë°˜ì˜

ab_proba_test = models.predict_proba(X_test)[:, 1]

# ê¸°ì¤€ê°’ ì„¤ì • (ex: 0.5)
ab_pred_test = (ab_proba_test >= 0.5).astype(int)

# %%



