{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa2cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/MyDrive/data/í†µí•©_train_ë°ì´í„°.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from modules.feature_selector import selected_cols\n",
    "\n",
    "# âœ… ID, Segment í¬í•¨ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±\n",
    "final_cols = selected_cols + [\"ID\", \"Segment\"]\n",
    "\n",
    "# âœ… í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë¡œë“œ\n",
    "train_df = pd.read_parquet(file_path, columns=final_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f2974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_loader import map_categorical_columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from modules.feature_selector import selected_cols, generate_vif_derived_features, generate_e_features\n",
    "\n",
    "# Step 1. ID, Segment ì œì™¸í•œ ê°€ê³µ ëŒ€ìƒ ì»¬ëŸ¼ë§Œ ë¶„ë¦¬\n",
    "exclude_cols = [\"ID\", \"Segment\"]\n",
    "target_col = \"Segment\"\n",
    "categorical_cols = [col for col in train_df.columns if train_df[col].dtype == \"object\" and col not in exclude_cols]\n",
    "\n",
    "# Step 2. ë³µì‚¬ë³¸ ìƒì„±\n",
    "df_processed = train_df.copy()\n",
    "\n",
    "# Step 3. ì´ìƒê°’ ì²˜ë¦¬ + ë²”ì£¼í˜• ì¸ì½”ë”©\n",
    "for col in categorical_cols:\n",
    "    df_processed[col] = df_processed[col].replace(['?', 'ì•ŒíŒŒë²³', 'ê¸°íƒ€'], pd.NA)\n",
    "    le = LabelEncoder()\n",
    "    df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "\n",
    "# âœ… Step 4. ì´ ì‹œì ì—ì„œ íŒŒìƒë³€ìˆ˜ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ\n",
    "# ì˜ˆì‹œ) df_processed â†’ generate_derived_features(df_processed)\n",
    "df_processed = generate_e_features(df_processed) \n",
    "df_processed = generate_vif_derived_features(df_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Segment ë¬¸ì ë¼ë²¨ ì¸ì½”ë”©\n",
    "le_segment = LabelEncoder()\n",
    "df_processed[\"Segment\"] = le_segment.fit_transform(df_processed[\"Segment\"])\n",
    "\n",
    "# ì €ì¥í•´ë‘ë©´ ë‚˜ì¤‘ì— ì—­ë³€í™˜ ê°€ëŠ¥\n",
    "segment_label_mapping = dict(zip(le_segment.classes_, le_segment.transform(le_segment.classes_)))\n",
    "print(\"ğŸ“Œ Segment ë¼ë²¨ ë§¤í•‘:\", segment_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[\"target\"] = (df_processed[\"Segment\"] == 4).astype(int)  # Segment E â†’ 1, ë‚˜ë¨¸ì§€ â†’ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42842903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. X, y ë¶„ë¦¬\n",
    "X = df_processed.drop(columns=[\"ID\", \"Segment\", \"target\"])\n",
    "y = df_processed[\"target\"]\n",
    "print(\"âœ… X shape:\", X.shape)\n",
    "print(\"âœ… y ë¶„í¬:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b158ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratifyë¥¼ ì ìš©í•´ í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•œ ì±„ ë¶„ë¦¬\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,         # ê²€ì¦ì…‹ ë¹„ìœ¨ (20%)\n",
    "    random_state=42,       # ì¬í˜„ì„± ê³ ì •\n",
    "    stratify=y             # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€ (ë¶ˆê· í˜• ëŒ€ë¹„)\n",
    ")\n",
    "\n",
    "# í™•ì¸\n",
    "print(\"âœ… í•™ìŠµì…‹ í¬ê¸°:\", X_train.shape, y_train.shape)\n",
    "print(\"âœ… ê²€ì¦ì…‹ í¬ê¸°:\", X_val.shape, y_val.shape)\n",
    "print(\"âœ… í•™ìŠµì…‹ í´ë˜ìŠ¤ ë¶„í¬:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"âœ… ê²€ì¦ì…‹ í´ë˜ìŠ¤ ë¶„í¬:\\n\", y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "# XGBoost DMatrix ë³€í™˜\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# GPU ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "best_params = {\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.2435,\n",
    "    'min_child_weight': 9,\n",
    "    'subsample': 0.6043,\n",
    "    'colsample_bytree': 0.8550,\n",
    "    'gamma': 3.3658,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'tree_method': 'hist',   # ìµœì‹ ë²„ì „ ê¸°ì¤€\n",
    "    'device': 'cuda',        # GPU ì‚¬ìš©\n",
    "    'use_label_encoder': False\n",
    "}\n",
    "\n",
    "# í•™ìŠµ\n",
    "model = XGBClassifier(**best_params, verbosity=0)\n",
    "model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
