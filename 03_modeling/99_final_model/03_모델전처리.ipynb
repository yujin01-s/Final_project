{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa2cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/MyDrive/data/통합_train_데이터.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94e571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from modules.feature_selector import selected_cols\n",
    "\n",
    "# ✅ ID, Segment 포함 컬럼 리스트 구성\n",
    "final_cols = selected_cols + [\"ID\", \"Segment\"]\n",
    "\n",
    "# ✅ 필요한 컬럼만 로드\n",
    "train_df = pd.read_parquet(file_path, columns=final_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f2974",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.data_loader import map_categorical_columns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from modules.feature_selector import selected_cols, generate_vif_derived_features, generate_e_features\n",
    "\n",
    "# Step 1. ID, Segment 제외한 가공 대상 컬럼만 분리\n",
    "exclude_cols = [\"ID\", \"Segment\"]\n",
    "target_col = \"Segment\"\n",
    "categorical_cols = [col for col in train_df.columns if train_df[col].dtype == \"object\" and col not in exclude_cols]\n",
    "\n",
    "# Step 2. 복사본 생성\n",
    "df_processed = train_df.copy()\n",
    "\n",
    "# Step 3. 이상값 처리 + 범주형 인코딩\n",
    "for col in categorical_cols:\n",
    "    df_processed[col] = df_processed[col].replace(['?', '알파벳', '기타'], pd.NA)\n",
    "    le = LabelEncoder()\n",
    "    df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "\n",
    "# ✅ Step 4. 이 시점에서 파생변수 생성 함수 호출\n",
    "# 예시) df_processed → generate_derived_features(df_processed)\n",
    "df_processed = generate_e_features(df_processed) \n",
    "df_processed = generate_vif_derived_features(df_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b27332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Segment 문자 라벨 인코딩\n",
    "le_segment = LabelEncoder()\n",
    "df_processed[\"Segment\"] = le_segment.fit_transform(df_processed[\"Segment\"])\n",
    "\n",
    "# 저장해두면 나중에 역변환 가능\n",
    "segment_label_mapping = dict(zip(le_segment.classes_, le_segment.transform(le_segment.classes_)))\n",
    "print(\"📌 Segment 라벨 매핑:\", segment_label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8034b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed[\"target\"] = (df_processed[\"Segment\"] == 4).astype(int)  # Segment E → 1, 나머지 → 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42842903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. X, y 분리\n",
    "X = df_processed.drop(columns=[\"ID\", \"Segment\", \"target\"])\n",
    "y = df_processed[\"target\"]\n",
    "print(\"✅ X shape:\", X.shape)\n",
    "print(\"✅ y 분포:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b158ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Stratify를 적용해 클래스 비율을 유지한 채 분리\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,         # 검증셋 비율 (20%)\n",
    "    random_state=42,       # 재현성 고정\n",
    "    stratify=y             # 클래스 비율 유지 (불균형 대비)\n",
    ")\n",
    "\n",
    "# 확인\n",
    "print(\"✅ 학습셋 크기:\", X_train.shape, y_train.shape)\n",
    "print(\"✅ 검증셋 크기:\", X_val.shape, y_val.shape)\n",
    "print(\"✅ 학습셋 클래스 분포:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"✅ 검증셋 클래스 분포:\\n\", y_val.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "# XGBoost DMatrix 변환\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "# GPU 기반 파라미터 설정\n",
    "best_params = {\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.2435,\n",
    "    'min_child_weight': 9,\n",
    "    'subsample': 0.6043,\n",
    "    'colsample_bytree': 0.8550,\n",
    "    'gamma': 3.3658,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss',\n",
    "    'tree_method': 'hist',   # 최신버전 기준\n",
    "    'device': 'cuda',        # GPU 사용\n",
    "    'use_label_encoder': False\n",
    "}\n",
    "\n",
    "# 학습\n",
    "model = XGBClassifier(**best_params, verbosity=0)\n",
    "model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
