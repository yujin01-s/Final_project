from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, f1_score
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from imblearn.over_sampling import RandomOverSampler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import f1_score
from sklearn.metrics import precision_score, recall_score
import matplotlib.pyplot as plt
import json

import os
import joblib

import numpy as np
import pandas as pd

def preprocess_and_split(X, y, test_size=0.2):
    # ìŠ¤ì¼€ì¼ë§ ì ìš© O
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
    print("âœ”ï¸ Standard Scaler ì ìš© ì™„ë£Œ.")
    # ë¼ë²¨ì¸ì½”ë”© ì ìš© O
    le_y = LabelEncoder()
    y_encoded = le_y.fit_transform(y)
    print("âœ”ï¸ LabelEncoding ì ìš© ì™„ë£Œ.")
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (test_size=ê¸°ë³¸0.2)
    X_train, X_val, y_train, y_val = train_test_split(
        X_scaled, y_encoded, test_size=test_size, stratify=y_encoded, random_state=42
    )
    print(f"âœ”ï¸ Test Data ë¶„ë¦¬ ì ìš© ì™„ë£Œ. size = {test_size}")
    return X_train, X_val, y_train, y_val, scaler, le_y

# âœ… XGBoost
def get_xgb_model(params=None):
    default_params = {
        'tree_method': 'hist',
        'device': 'cuda', 
        'n_estimators': 300,
        'learning_rate': 0.05,
        'max_depth': 6,
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'eval_metric': 'mlogloss',
        'random_state': 42
    }
    if params:
        default_params.update(params)
    
    model = XGBClassifier(**default_params)
    print("ğŸ§  XGBoost ëª¨ë¸ ì •ì˜ ì™„ë£Œ")
    return model

# âœ… LightGBM
def get_lgbm_model(params=None):
    default_params = {
        "n_estimators": 300,
        "learning_rate": 0.05,
        "max_depth": 6,
        "random_state": 42,
        "n_jobs": -1
    }
    if params:
        default_params.update(params)
    print("ğŸ’¡ LightGBM ëª¨ë¸ ì •ì˜ ì™„ë£Œ")
    return LGBMClassifier(**default_params)

# âœ… RandomForest
def get_rf_model(params=None):
    default_params = {
        "n_estimators": 300,
        "max_depth": 10,
        "random_state": 42,
        "n_jobs": -1
    }
    if params:
        default_params.update(params)
    print("ğŸŒ² RandomForest ëª¨ë¸ ì •ì˜ ì™„ë£Œ")
    return RandomForestClassifier(**default_params)

# âœ… LogisticRegression (ë©”íƒ€ëª¨ë¸ìš© ë“±)
def get_lr_model(params=None):
    default_params = {
        "max_iter": 1000,
        "random_state": 42
    }
    if params:
        default_params.update(params)
    print("ğŸ“ˆ LogisticRegression ëª¨ë¸ ì •ì˜ ì™„ë£Œ")
    return LogisticRegression(**default_params)

# ëª¨ë¸ ë§¤í•‘
MODEL_FUNC_MAP = {
    "xgb": get_xgb_model,
    "rf": get_rf_model,
    "lgbm": get_lgbm_model,
    "lr": get_lr_model
}

def get_model(name: str, params: dict = None):
    name = name.lower()
    if name not in MODEL_FUNC_MAP:
        raise ValueError(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì´ë¦„ì…ë‹ˆë‹¤: {name}")
    
    model_func = MODEL_FUNC_MAP[name]         # â¬…ï¸ í•¨ìˆ˜ ìì²´ ê°€ì ¸ì˜´
    model = model_func(params)                # â¬…ï¸ í˜¸ì¶œ
    print(f"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ: {name.upper()}")
    return model

# ì„±ëŠ¥í‰ê°€ì§€í‘œ í•¨ìˆ˜
def train_and_evaluate(model, X_train, y_train, X_val, y_val, model_name=None):
    model_name = model_name or type(model).__name__
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)
    print(f"âœ… [{model_name}]")
    print("ğŸ“Š ì„±ëŠ¥ í‰ê°€:")
    print(classification_report(y_val, y_pred))

    print("F1 Macro :", f1_score(y_val, y_pred, average='macro'))
    print("F1 Micro :", f1_score(y_val, y_pred, average='micro'))
    print("F1 Weighted :", f1_score(y_val, y_pred, average='weighted'))
    
    return model

#SMOTE ì ìš©
def apply_smote(X_train, y_train, random_state=42, **smote_kwargs):
    """
    SMOTEë¥¼ ì ìš©í•´ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ë³´ì •í•©ë‹ˆë‹¤. ì¶”ê°€ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë„ ì§€ì›í•©ë‹ˆë‹¤.
    
    Args:
        X_train (DataFrame or ndarray): í•™ìŠµ ì…ë ¥ í”¼ì²˜
        y_train (Series or ndarray): í•™ìŠµ íƒ€ê²Ÿ
        random_state (int): ëœë¤ ì‹œë“œ (ê¸°ë³¸ê°’: 42)
        **smote_kwargs: SMOTEì— ì „ë‹¬í•  ì¶”ê°€ íŒŒë¼ë¯¸í„° (k_neighbors ë“±)
        
    Returns:
        X_resampled, y_resampled: í´ë˜ìŠ¤ ê· í˜•ì´ ë§ì¶°ì§„ í•™ìŠµ ë°ì´í„°ì…‹
    """
    smote = SMOTE(random_state=random_state, **smote_kwargs)
    X_resampled, y_resampled = smote.fit_resample(X_train, y_train)
    
    print("âœ… SMOTE ì ìš© ì™„ë£Œ")
    print(f"  â†’ Before: {len(y_train)} samples")
    print(f"  â†’ After:  {len(y_resampled)} samples (class balanced)")
    
    return X_resampled, y_resampled

# ì˜¤ë²„ìƒ˜í”Œë§ í•¨ìˆ˜
def apply_oversampling(X_scaled, y_encoded, strategy=None):
    """
    ì˜¤ë²„ìƒ˜í”Œë§ í•¨ìˆ˜ (ì¶”í›„ ì „ëµ ìˆ˜ì¹˜ íŠœë‹ ê°€ëŠ¥)

    Args:
        X_scaled: ìŠ¤ì¼€ì¼ë§ëœ í”¼ì²˜
        y_encoded: ì¸ì½”ë”©ëœ íƒ€ê²Ÿ
        strategy: sampling_strategy ë”•ì…”ë„ˆë¦¬ (ì˜ˆ: {0:1500, 1:3000})

    Returns:
        X_resampled, y_resampled
    """
    strategy = strategy or {0: 1500, 1: 3000}  # ê¸°ë³¸ê°’ ì§€ì •
    ros = RandomOverSampler(sampling_strategy=strategy, random_state=42)
    X_resampled, y_resampled = ros.fit_resample(X_scaled, y_encoded)

    print("\ud83d\udd01 ì˜¤ë²„ìƒ˜í”Œë§ ì™„ë£Œ:", pd.Series(y_resampled).value_counts())

    return np.array(X_resampled), np.array(y_resampled)

# Threshold ì‹œê°í™”
def plot_threshold_metrics(model, X_val, y_val, positive_class=1, thresholds=np.linspace(0.1, 0.9, 50)):
    """
    ë‹¤ì–‘í•œ thresholdì— ëŒ€í•´ F1, Precision, Recall ì‹œê°í™”

    Args:
        model: í™•ë¥  ì˜ˆì¸¡ì´ ê°€ëŠ¥í•œ í•™ìŠµëœ ëª¨ë¸
        X_val: ê²€ì¦ ë°ì´í„°
        y_val: ì •ë‹µ ë ˆì´ë¸”
        positive_class: ê´€ì‹¬ ìˆëŠ” positive í´ë˜ìŠ¤ ì¸ë±ìŠ¤ (binary ë¶„ë¥˜ ê¸°ì¤€)
        thresholds: ì‹¤í—˜í•  threshold ë¦¬ìŠ¤íŠ¸
    """
    y_proba = model.predict_proba(X_val)[:, positive_class]

    f1_scores = []
    precision_scores = []
    recall_scores = []

    for t in thresholds:
        y_pred_thresh = (y_proba > t).astype(int)
        f1_scores.append(f1_score(y_val, y_pred_thresh))
        precision_scores.append(precision_score(y_val, y_pred_thresh))
        recall_scores.append(recall_score(y_val, y_pred_thresh))

    plt.figure(figsize=(10, 6))
    plt.plot(thresholds, f1_scores, label='F1 Score', marker='o')
    plt.plot(thresholds, precision_scores, label='Precision', marker='s')
    plt.plot(thresholds, recall_scores, label='Recall', marker='^')
    plt.xlabel("Threshold")
    plt.ylabel("Score")
    plt.title("Threshold vs F1 / Precision / Recall")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# ìµœì  threshold ì°¾ê¸°
def apply_best_threshold(model, X_val, y_val, positive_class=1, thresholds=np.linspace(0.1, 0.9, 50)):
    # ë‹¤ì¤‘ í´ë˜ìŠ¤ yë¥¼ binaryë¡œ ë°”ê¾¸ê¸°
    if y_val.dtype != int and y_val.dtype != bool:
        y_val = (y_val == positive_class).astype(int)

    y_proba = model.predict_proba(X_val)[:, 1]

    best_f1 = 0
    best_threshold = 0.5
    y_pred_best = None

    for t in thresholds:
        y_pred = (y_proba > t).astype(int)
        f1 = f1_score(y_val, y_pred)
        if f1 > best_f1:
            best_f1 = f1
            best_threshold = t
            y_pred_best = y_pred

    print(f"\nğŸŒŸ ìµœì  Threshold: {best_threshold:.3f} (F1 Score: {best_f1:.4f})")
    return best_threshold, best_f1, y_pred_best


# ëª¨ë¸ & ê²°ê³¼ ì €ì¥
def save_model_and_results(model, model_name, result_df=None, save_path="./outputs"):
    """
    ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥ìš© ê³µí†µ í•¨ìˆ˜
    """
    os.makedirs(save_path, exist_ok=True)
    model_path = f"{save_path}/{model_name}.pkl"
    joblib.dump(model, model_path)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_path}")

    if result_df is not None:
        csv_path = f"{save_path}/experiment_results.csv"
        result_df.to_csv(csv_path, index=False)
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_path}")

def save_experiment_summary(model_name, save_path, threshold=None, f1_score=None, extra_info=None):
    """
    threshold, f1, ê¸°íƒ€ ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥
    """
    os.makedirs(save_path, exist_ok=True)
    summary = {
        "model_name": model_name,
        "best_threshold": threshold,
        "best_f1": f1_score
    }
    if extra_info:
        summary.update(extra_info)

    path = os.path.join(save_path, f"{model_name}_summary.json")
    with open(path, "w") as f:
        json.dump(summary, f, indent=2)

    print(f"ğŸ“„ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {path}")

def combine_segment_predictions(pred_e, pred_ab, pred_cd):
    """
    E, AB, CD ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê²°í•©í•˜ì—¬ ìµœì¢… Segmentë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Parameters:
    - pred_e (list[int] or np.array): E ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ (4 ë˜ëŠ” 0)
    - pred_ab (list[int] or np.array): AB ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ (0 ë˜ëŠ” 1)
    - pred_cd (list[int] or np.array): CD ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ (2 ë˜ëŠ” 3)

    Returns:
    - final_preds (list[int]): í†µí•©ëœ ìµœì¢… Segment (0~4)
    """
    final_preds = []
    for e, ab, cd in zip(pred_e, pred_ab, pred_cd):
        if e == 4:
            final_preds.append(4)  # âœ… E ìš°ì„ 
        elif ab in [0, 1]:
            final_preds.append(ab)  # ê·¸ë‹¤ìŒ AB
        elif cd in [2, 3]:
            final_preds.append(cd)  # ë§ˆì§€ë§‰ CD
        else:
            final_preds.append(-1)  # ì˜ˆì™¸ ì²˜ë¦¬ìš© (optional)
    return final_preds

import numpy as np

def custom_threshold(proba, thresh_dict, default_class=2):
    """
    ë‹¤ì¤‘ë¶„ë¥˜ ëª¨ë¸ì˜ í™•ë¥  ì˜ˆì¸¡ ê²°ê³¼ì—ì„œ í´ë˜ìŠ¤ë³„ threshold ê¸°ì¤€ìœ¼ë¡œ ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤ ê²°ì •

    Args:
        proba: shape (n_samples, n_classes), predict_proba ê²°ê³¼
        thresh_dict: {class_index: threshold_value}
        default_class: ì–´ë–¤ í´ë˜ìŠ¤ë„ ê¸°ì¤€ í†µê³¼í•˜ì§€ ëª»í–ˆì„ ê²½ìš° ê¸°ë³¸ìœ¼ë¡œ ì˜ˆì¸¡í•  í´ë˜ìŠ¤

    Returns:
        preds: shape (n_samples,), threshold ê¸°ë°˜ ì˜ˆì¸¡ ë¼ë²¨
    """
    preds = []
    for row in proba:
        # threshold ë„˜ëŠ” í´ë˜ìŠ¤ë§Œ í•„í„°ë§
        valid_classes = [cls for cls, thresh in thresh_dict.items() if row[cls] >= thresh]
        if valid_classes:
            # ë„˜ì€ ê²ƒ ì¤‘ ê°€ì¥ í™•ë¥  ë†’ì€ í´ë˜ìŠ¤ ì„ íƒ
            pred_class = max(valid_classes, key=lambda cls: row[cls])
            preds.append(pred_class)
        else:
            preds.append(default_class)
    return np.array(preds)

import joblib

def save_xgb_model(model, path):
    """
    XGBClassifier ì „ì²´ ê°ì²´ ì €ì¥ (í•˜ì´í¼íŒŒë¼ë¯¸í„° í¬í•¨)
    """
    joblib.dump(model, path)
    print(f"âœ… ëª¨ë¸ ì „ì²´ ì €ì¥ ì™„ë£Œ: {path}")

def load_xgb_model(path):
    """
    ì €ì¥ëœ XGBClassifier ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    """
    model = joblib.load(path)
    print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {path}")
    return model
