import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from modules.feature_selector import stage_feature_map

from modules.preprocess_utils import (
    map_categorical_columns,
    encode_categorical_columns
)

def load_and_process(file_path: str,
                     stage: str = None,
                     selected_cols: list = None,
                     base_cols: list = ["ID", "Segment"]):
    """
    íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³ , stage ë˜ëŠ” selected_cols ê¸°ë°˜ìœ¼ë¡œ ì»¬ëŸ¼ì„ ì¶”ì¶œ + ë²”ì£¼í˜• ì¸ì½”ë”©

    Returns:
    - df_final (pd.DataFrame): base_cols + ê°€ê³µëœ ì»¬ëŸ¼
    - used_columns (list): ê°€ê³µ ëŒ€ìƒ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (base ì œì™¸)
    """
    import pandas as pd
    from sklearn.preprocessing import LabelEncoder

    # 1. íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    if file_path.endswith(".parquet"):
        df = pd.read_parquet(file_path)
    elif file_path.endswith(".csv"):
        df = pd.read_csv(file_path)
    else:
        raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
    print("ğŸ“‚ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ")

    # 2. stage ê¸°ë°˜ selected_cols ì„¤ì •
    if stage is not None:
        if stage not in stage_feature_map:
            raise ValueError(f"'{stage}'ëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        selected_cols = stage_feature_map[stage]

    # 3. base_colsì—ì„œ ì—†ëŠ” ì»¬ëŸ¼ ì œê±°
    filtered_base_cols = [col for col in base_cols if col in df.columns]

    # 4. ì»¬ëŸ¼ í•„í„°ë§
    if selected_cols is not None:
        keep_cols = list(set(filtered_base_cols + selected_cols))
        df = df[keep_cols]

    # 5. ì¤‘ë³µ ì»¬ëŸ¼ ì œê±°
    df = df.loc[:, ~df.columns.duplicated()]

    # 6. ì‚¬ìš©ì ì •ì˜ ë§¤í•‘
    df = map_categorical_columns(df)

    # 7. ë²”ì£¼í˜• ì¸ì½”ë”© (IDëŠ” ì œì™¸!)
    object_cols = [col for col in df.select_dtypes(include='object').columns if col != "ID"]
    for col in object_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))

    print("âœ… ë²”ì£¼í˜• ì¸ì½”ë”© ì™„ë£Œ")

    used_columns = [col for col in df.columns if col not in filtered_base_cols]
    return df, used_columns


def test_load(path: str, scaler: StandardScaler = None):
    """
    í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© + ì „ì²˜ë¦¬ (íƒ€ê²Ÿ ì—†ìŒ)
    Args:
        path (str): í†µí•©ëœ parquet í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ
        scaler (StandardScaler): trainì—ì„œ ì‚¬ìš©í•œ ìŠ¤ì¼€ì¼ëŸ¬ ê°ì²´

    Returns:
        X_test (DataFrame): ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    """
    print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘: {path}")
    df = pd.read_parquet(path)

    X = df.copy()
    X = X.loc[:, ~X.columns.duplicated()]

    # ì „ì²˜ë¦¬ ë™ì¼í•˜ê²Œ ì ìš©
    X = map_categorical_columns(X)
    X = encode_categorical_columns(X)

    imputer = SimpleImputer(strategy='mean')
    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

    if scaler:
        X = pd.DataFrame(scaler.transform(X), columns=X.columns)
        print("ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì ìš© ì™„ë£Œ")

    print(f"âœ… test_load ì™„ë£Œ: X={X.shape}")
    return X
