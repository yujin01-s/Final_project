{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eddf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ PC1~PC5ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ì¤‘ìš”í•œ ë³€ìˆ˜:\n",
    "pca_cols = [\n",
    "    'CAì´ììœ¨_í• ì¸ì „', 'CLì´ììœ¨_í• ì¸ì „', 'RV_í‰ê· ì”ì•¡_R3M', 'RVì¼ì‹œë¶ˆì´ììœ¨_í• ì¸ì „', 'RVìµœì†Œê²°ì œë¹„ìœ¨', 'RVí˜„ê¸ˆì„œë¹„ìŠ¤ì´ììœ¨_í• ì¸ì „', \n",
    "    'ë°©ë¬¸ì›”ìˆ˜_ì•±_R6M', 'ë°©ë¬¸ì¼ìˆ˜_ì•±_B0M', 'ë°©ë¬¸ì¼ìˆ˜_ì•±_R6M', 'ë°©ë¬¸íšŸìˆ˜_ì•±_B0M', 'ë°©ë¬¸í›„ê²½ê³¼ì›”_ì•±_R6M', \n",
    "    'ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©', 'ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©ì²´í¬', 'ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_B0M', 'ì´ìš©ê¸ˆì•¡ëŒ€', \n",
    "    'ì¼ì‹œë¶ˆONLYì „í™˜ê°€ëŠ¥ì—¬ë¶€', \n",
    "    'ì”ì•¡_ë¦¬ë³¼ë¹™ì¼ì‹œë¶ˆì´ì›”_B0M', 'ì”ì•¡_ì¼ì‹œë¶ˆ_B0M', 'ì”ì•¡_ì¼ì‹œë¶ˆ_B1M', 'ì”ì•¡_ì¼ì‹œë¶ˆ_B2M', 'ì”ì•¡_ì¹´ë“œë¡ _B0M', 'ì”ì•¡_ì¹´ë“œë¡ _B1M', 'ì”ì•¡_ì¹´ë“œë¡ _B2M', 'ì”ì•¡_ì¹´ë“œë¡ _B3M', 'ì”ì•¡_ì¹´ë“œë¡ _B4M', 'ì”ì•¡_ì¹´ë“œë¡ _B5M', \n",
    "    'ì •ìƒì²­êµ¬ì›ê¸ˆ_B0M', 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B2M', 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M', \n",
    "    'ì²­êµ¬ê¸ˆì•¡_B0', 'ì²­êµ¬ê¸ˆì•¡_R3M', 'ì²­êµ¬ê¸ˆì•¡_R6M', 'ìµœì¢…ì¹´ë“œë¡ _ëŒ€ì¶œê¸ˆì•¡', 'ì¹´ë“œë¡ ì´ìš©ê¸ˆì•¡_ëˆ„ì ', 'í‰ì”_RVì¼ì‹œë¶ˆ_3M', 'í‰ì”_RVì¼ì‹œë¶ˆ_6M', 'í‰ì”_ì¼ì‹œë¶ˆ_3M', 'í‰ì”_ì¼ì‹œë¶ˆ_6M', \n",
    "    'í‰ì”_ì¹´ë“œë¡ _3M', 'í‰ì”_ì¹´ë“œë¡ _6M', 'í‰ì”_í• ë¶€_3M', 'í™ˆí˜ì´ì§€_ê¸ˆìœµê±´ìˆ˜_R3M', 'í™ˆí˜ì´ì§€_ê¸ˆìœµê±´ìˆ˜_R6M', 'í™ˆí˜ì´ì§€_ì„ ê²°ì œê±´ìˆ˜_R3M', 'í™ˆí˜ì´ì§€_ì„ ê²°ì œê±´ìˆ˜_R6M'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "544e934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cols = [\"ID\",\"Segment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78c8e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = pca_cols + base_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9356e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "file_path = \"../../data/í†µí•©_train_ë°ì´í„°.parquet\"\n",
    "df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3904bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(len(selected_cols))         \n",
    "print(type(selected_cols[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9337062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_categorical_columns(df, verbose=True):\n",
    "    \"\"\"\n",
    "    ë¯¸ë¦¬ ì •ì˜ëœ ë§¤í•‘ ê¸°ì¤€ì— ë”°ë¼ ë²”ì£¼í˜• ì»¬ëŸ¼ë“¤ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    ì²˜ë¦¬ ì»¬ëŸ¼: ê±°ì£¼ì‹œë„ëª…, ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M, í•œë„ì¦ì•¡íšŸìˆ˜_R12M, ì´ìš©ê¸ˆì•¡ëŒ€,\n",
    "              í• ì¸ê±´ìˆ˜_R3M, í• ì¸ê±´ìˆ˜_B0M, ë°©ë¬¸íšŸìˆ˜_PC_R6M, ë°©ë¬¸íšŸìˆ˜_ì•±_R6M, ë°©ë¬¸ì¼ìˆ˜_PC_R6M\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. ê±°ì£¼ì‹œë„ëª… â†’ ìˆ˜ë„ê¶Œ ì—¬ë¶€\n",
    "    capital_area = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ê²½ê¸°ë„', 'ì¸ì²œê´‘ì—­ì‹œ']\n",
    "    if 'ê±°ì£¼ì‹œë„ëª…' in df.columns:\n",
    "        df['ê±°ì£¼ì‹œë„_ìˆ˜ë„ê¶Œì—¬ë¶€'] = df['ê±°ì£¼ì‹œë„ëª…'].apply(lambda x: 1 if x in capital_area else 0)\n",
    "        df.drop(columns=['ê±°ì£¼ì‹œë„ëª…'], inplace=True)\n",
    "        if verbose: print(\"[ê±°ì£¼ì‹œë„ëª…] â†’ ìˆ˜ë„ê¶Œ ì—¬ë¶€ ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 2. ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M\n",
    "    mapping = {\"0ê°œ\": 0, \"1ê°œì´ìƒ\": 1}\n",
    "    if 'ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M' in df.columns:\n",
    "        df['ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M'] = df['ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M'].map(mapping).astype(int)\n",
    "        if verbose: print(\"[ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M] ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 3. í•œë„ì¦ì•¡íšŸìˆ˜_R12M\n",
    "    mapping = {\"0íšŒ\": 0, \"1íšŒì´ìƒ\": 1}\n",
    "    if 'í•œë„ì¦ì•¡íšŸìˆ˜_R12M' in df.columns:\n",
    "        df['í•œë„ì¦ì•¡íšŸìˆ˜_R12M'] = df['í•œë„ì¦ì•¡íšŸìˆ˜_R12M'].map(mapping).astype(int)\n",
    "        if verbose: print(\"[í•œë„ì¦ì•¡íšŸìˆ˜_R12M] ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 4. ì´ìš©ê¸ˆì•¡ëŒ€ (ì¤‘ê°„ê°’ ê¸°ì¤€: ë§Œì› ë‹¨ìœ„)\n",
    "    mapping = {\n",
    "        \"09.ë¯¸ì‚¬ìš©\": 0,\n",
    "        \"05.10ë§Œì›-\": 5,\n",
    "        \"04.10ë§Œì›+\": 20,\n",
    "        \"03.30ë§Œì›+\": 40,\n",
    "        \"02.50ë§Œì›+\": 75,\n",
    "        \"01.100ë§Œì›+\": 150\n",
    "    }\n",
    "    if 'ì´ìš©ê¸ˆì•¡ëŒ€' in df.columns:\n",
    "        df['ì´ìš©ê¸ˆì•¡ëŒ€'] = df['ì´ìš©ê¸ˆì•¡ëŒ€'].map(mapping)\n",
    "        if verbose: print(\"[ì´ìš©ê¸ˆì•¡ëŒ€] ì¤‘ê°„ê°’ ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 5. í• ì¸ê±´ìˆ˜ ì¸ì½”ë”©\n",
    "    discount_map = {\n",
    "        \"1íšŒ ì´ìƒ\": 1,\n",
    "        \"10íšŒ ì´ìƒ\": 10,\n",
    "        \"20íšŒ ì´ìƒ\": 20,\n",
    "        \"30íšŒ ì´ìƒ\": 30,\n",
    "        \"40íšŒ ì´ìƒ\": 40\n",
    "    }\n",
    "    for col in ['í• ì¸ê±´ìˆ˜_R3M', 'í• ì¸ê±´ìˆ˜_B0M']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(discount_map).astype(int)\n",
    "            if verbose: print(f\"[{col}] ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 6. ë°©ë¬¸íšŸìˆ˜ ë° ë°©ë¬¸ì¼ìˆ˜ ì¸ì½”ë”©\n",
    "    visit_map = {\n",
    "        \"1íšŒ ì´ìƒ\": 1,\n",
    "        \"10íšŒ ì´ìƒ\": 10,\n",
    "        \"20íšŒ ì´ìƒ\": 20,\n",
    "        \"30íšŒ ì´ìƒ\": 30,\n",
    "        \"40íšŒ ì´ìƒ\": 40,\n",
    "        \"50íšŒ ì´ìƒ\": 50,\n",
    "        \"60íšŒ ì´ìƒ\": 60,\n",
    "        \"70íšŒ ì´ìƒ\": 70,\n",
    "        \"80íšŒ ì´ìƒ\": 80\n",
    "    }\n",
    "\n",
    "    visit_cols = ['ë°©ë¬¸íšŸìˆ˜_PC_R6M', 'ë°©ë¬¸íšŸìˆ˜_ì•±_R6M', 'ë°©ë¬¸ì¼ìˆ˜_PC_R6M']\n",
    "    for col in visit_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(visit_map).astype(int)\n",
    "            if verbose: print(f\"[{col}] ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c972e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ê±°ì£¼ì‹œë„ëª…] â†’ ìˆ˜ë„ê¶Œ ì—¬ë¶€ ì¸ì½”ë”© ì™„ë£Œ\n",
      "[ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M] ì¸ì½”ë”© ì™„ë£Œ\n",
      "[í•œë„ì¦ì•¡íšŸìˆ˜_R12M] ì¸ì½”ë”© ì™„ë£Œ\n",
      "[ì´ìš©ê¸ˆì•¡ëŒ€] ì¤‘ê°„ê°’ ì¸ì½”ë”© ì™„ë£Œ\n",
      "[í• ì¸ê±´ìˆ˜_R3M] ì¸ì½”ë”© ì™„ë£Œ\n",
      "[í• ì¸ê±´ìˆ˜_B0M] ì¸ì½”ë”© ì™„ë£Œ\n",
      "[ë°©ë¬¸íšŸìˆ˜_PC_R6M] ì¸ì½”ë”© ì™„ë£Œ\n",
      "[ë°©ë¬¸íšŸìˆ˜_ì•±_R6M] ì¸ì½”ë”© ì™„ë£Œ\n",
      "[ë°©ë¬¸ì¼ìˆ˜_PC_R6M] ì¸ì½”ë”© ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\somee\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:13:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\somee\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [14:13:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"predictor\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\somee\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2676: UserWarning: [14:14:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  if len(data.shape) != 1 and self.num_features() != data.shape[1]:\n",
      "c:\\Users\\somee\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729: UserWarning: [14:14:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\common\\error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.24      0.37       194\n",
      "           1       1.00      0.28      0.43        29\n",
      "           2       0.71      0.55      0.62     25518\n",
      "           3       0.68      0.60      0.64     69848\n",
      "           4       0.93      0.97      0.95    384411\n",
      "\n",
      "    accuracy                           0.89    480000\n",
      "   macro avg       0.83      0.53      0.60    480000\n",
      "weighted avg       0.88      0.89      0.89    480000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_parquet(\"../../data/í†µí•©_train_ë°ì´í„°.parquet\")\n",
    "\n",
    "# 2. í”¼ì²˜ ë° íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "X = df[selected_cols].copy()\n",
    "y = df[\"Segment\"]\n",
    "\n",
    "X = X.loc[:, ~X.columns.duplicated()] #ì¤‘ë³µì œê±°\n",
    "\n",
    "# 3. ë²”ì£¼í˜• ì¸ì½”ë”©\n",
    "df = map_categorical_columns(df)\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# 4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X), columns=X.columns)\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§ (DataFrame í˜•íƒœ ìœ ì§€)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# ë¼ë²¨ì¸ì½”ë”©\n",
    "le_y = LabelEncoder()\n",
    "y_encoded = le_y.fit_transform(y)\n",
    "\n",
    "# 6. train-validation ë¶„í• \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "# 7. XGBoost ëª¨ë¸ ì„ ì–¸ (GPU ê°€ì†)\n",
    "xgb_model = XGBClassifier(\n",
    "    tree_method='gpu_hist',\n",
    "    predictor='gpu_predictor',\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 8. í•™ìŠµ\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 9. ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d141fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
