{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94eddf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📌 PC1~PC5에서 반복적으로 중요한 변수:\n",
    "pca_cols = [\n",
    "    'CA이자율_할인전', 'CL이자율_할인전', 'RV_평균잔액_R3M', 'RV일시불이자율_할인전', 'RV최소결제비율', 'RV현금서비스이자율_할인전', \n",
    "    '방문월수_앱_R6M', '방문일수_앱_B0M', '방문일수_앱_R6M', '방문횟수_앱_B0M', '방문후경과월_앱_R6M', \n",
    "    '이용금액_R3M_신용', '이용금액_R3M_신용체크', '이용금액_일시불_B0M', '이용금액대', \n",
    "    '일시불ONLY전환가능여부', \n",
    "    '잔액_리볼빙일시불이월_B0M', '잔액_일시불_B0M', '잔액_일시불_B1M', '잔액_일시불_B2M', '잔액_카드론_B0M', '잔액_카드론_B1M', '잔액_카드론_B2M', '잔액_카드론_B3M', '잔액_카드론_B4M', '잔액_카드론_B5M', \n",
    "    '정상청구원금_B0M', '정상청구원금_B2M', '정상청구원금_B5M', \n",
    "    '청구금액_B0', '청구금액_R3M', '청구금액_R6M', '최종카드론_대출금액', '카드론이용금액_누적', '평잔_RV일시불_3M', '평잔_RV일시불_6M', '평잔_일시불_3M', '평잔_일시불_6M', \n",
    "    '평잔_카드론_3M', '평잔_카드론_6M', '평잔_할부_3M', '홈페이지_금융건수_R3M', '홈페이지_금융건수_R6M', '홈페이지_선결제건수_R3M', '홈페이지_선결제건수_R6M'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544e934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cols = [\"ID\",\"Segment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c8e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = pca_cols + base_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9356e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a\n",
      "0  1\n",
      "1  2\n",
      "2  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 14:11:07,765 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53975 (pid=17420) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:10,276 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53971 (pid=18892) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:10,416 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:10,684 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53969 (pid=6272) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:11,363 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53969' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123', 'lambda-e96255760db5f9bd771cb86b70bd1eb2'} (stimulus_id='handle-worker-cleanup-1752124271.3626504')\n",
      "2025-07-10 14:11:11,730 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53967 (pid=18604) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:12,165 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53967' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-f21ed0a8a83a60e0703ffc2cd176ce6c'} (stimulus_id='handle-worker-cleanup-1752124272.1654265')\n",
      "2025-07-10 14:11:12,167 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:53967' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-19cec8dca68749e79ac1ea7ea87acc91'} (stimulus_id='handle-worker-cleanup-1752124272.1654265')\n",
      "2025-07-10 14:11:12,618 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53979 (pid=13244) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:12,677 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53970 (pid=19132) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:12,923 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53970' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-f40b8553ae0413f2b6f4a7a6e84f9015'} (stimulus_id='handle-worker-cleanup-1752124272.9228415')\n",
      "2025-07-10 14:11:13,296 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:13,580 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:14,898 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:14,935 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53968 (pid=24580) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:15,281 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53968' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124275.2792547')\n",
      "2025-07-10 14:11:15,283 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:53968' caused the cluster to lose scattered data, which can't be recovered: {'function-1cd8e093de65c88a610ccbb30fa7918c'} (stimulus_id='handle-worker-cleanup-1752124275.2792547')\n",
      "2025-07-10 14:11:16,074 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:16,225 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53982 (pid=18348) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:16,519 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53982' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-e34b938029db572383e28308d0e678d9'} (stimulus_id='handle-worker-cleanup-1752124276.5186963')\n",
      "2025-07-10 14:11:16,524 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:17,546 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53972 (pid=2800) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:18,170 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53972' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-fe35ad8d0e84a59a26425794e14b097b'} (stimulus_id='handle-worker-cleanup-1752124278.169662')\n",
      "2025-07-10 14:11:18,953 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:19,847 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:21,111 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:21,349 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53977 (pid=10272) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:21,352 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53976 (pid=4784) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:21,951 - distributed.scheduler - ERROR - Task parse-f278a817eaf6a8e4f8687977c860ea17 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:21,952 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53977' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-517eaebe6744c735eb2f46a2c64c1464'} (stimulus_id='handle-worker-cleanup-1752124281.9506702')\n",
      "2025-07-10 14:11:21,964 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53976' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b6c24d0bbcbce437e36f3f63f8d33f42'} (stimulus_id='handle-worker-cleanup-1752124281.9637914')\n",
      "2025-07-10 14:11:22,366 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53978 (pid=18436) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:23,514 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54039 (pid=6772) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:24,267 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54039' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124284.266864')\n",
      "2025-07-10 14:11:24,270 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:24,281 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:25,571 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:25,840 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:26,119 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54053 (pid=24544) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:26,759 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54053' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-7ac421c3f9263d6069f97f744f84d362'} (stimulus_id='handle-worker-cleanup-1752124286.7584589')\n",
      "2025-07-10 14:11:27,732 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54052 (pid=10448) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:28,228 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54052' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe', 'parse-c521d4f02a4118847b50f69e7209dd90'} (stimulus_id='handle-worker-cleanup-1752124288.2273602')\n",
      "2025-07-10 14:11:28,247 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:28,951 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54063 (pid=14608) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:29,414 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:29,422 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54063' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b6c24d0bbcbce437e36f3f63f8d33f42'} (stimulus_id='handle-worker-cleanup-1752124289.4211466')\n",
      "2025-07-10 14:11:30,404 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54070 (pid=22924) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:31,473 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:31,490 - distributed.scheduler - ERROR - Task parse-82f0fc78267c899855fabc8dcfb170a2 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:31,493 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54070' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-e34b938029db572383e28308d0e678d9'} (stimulus_id='handle-worker-cleanup-1752124291.4881847')\n",
      "2025-07-10 14:11:31,502 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54073 (pid=23684) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:32,352 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54073' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-c860748d8b3ffb5612067c2ce80abfcb'} (stimulus_id='handle-worker-cleanup-1752124292.3514655')\n",
      "2025-07-10 14:11:32,964 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:33,169 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54088 (pid=23564) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:33,515 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:33,533 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54094 (pid=23096) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:33,858 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54088' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124293.8579204')\n",
      "2025-07-10 14:11:33,866 - distributed.scheduler - ERROR - Task parse-f21ed0a8a83a60e0703ffc2cd176ce6c marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:35,340 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54100 (pid=24240) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:35,914 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54100' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b6c24d0bbcbce437e36f3f63f8d33f42', 'parse-7ac421c3f9263d6069f97f744f84d362'} (stimulus_id='handle-worker-cleanup-1752124295.9145947')\n",
      "2025-07-10 14:11:35,936 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:35,943 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:37,511 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:39,926 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54117 (pid=23144) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:41,034 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54117' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-6106482fed2984161e8f34d054b1d67d'} (stimulus_id='handle-worker-cleanup-1752124301.0327654')\n",
      "2025-07-10 14:11:41,842 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54137 (pid=10804) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:42,262 - distributed.scheduler - ERROR - Task parse-b6c24d0bbcbce437e36f3f63f8d33f42 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:42,264 - distributed.scheduler - ERROR - Task parse-c521d4f02a4118847b50f69e7209dd90 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:42,276 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54125 (pid=15596) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:43,055 - distributed.scheduler - ERROR - Task lambda-cd8131de10e0edaec093714fa3d7ec41 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:43,064 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54125' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124303.0524733')\n",
      "2025-07-10 14:11:43,179 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:43,271 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54114 (pid=24148) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:45,302 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54114' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123'} (stimulus_id='handle-worker-cleanup-1752124305.3022122')\n",
      "2025-07-10 14:11:45,310 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:46,378 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54128 (pid=23184) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:46,846 - distributed.scheduler - ERROR - Task parse-6106482fed2984161e8f34d054b1d67d marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:46,853 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54128' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe', 'parse-846372667560771c6f5279ab06086018'} (stimulus_id='handle-worker-cleanup-1752124306.8450594')\n",
      "2025-07-10 14:11:47,031 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:47,780 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:47,806 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54145 (pid=24760) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:48,689 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:49,768 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54145' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-312f0aa4f116c8836cb366b50329ee5e', 'parse-7ac421c3f9263d6069f97f744f84d362'} (stimulus_id='nanny-close-1752124308.675183')\n",
      "2025-07-10 14:11:50,978 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:51,066 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54166 (pid=10248) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:52,230 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54166' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-c860748d8b3ffb5612067c2ce80abfcb'} (stimulus_id='handle-worker-cleanup-1752124312.229281')\n",
      "2025-07-10 14:11:55,421 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:57,443 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54170 (pid=5624) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:58,531 - distributed.scheduler - ERROR - Task lambda-2d4ac82d2e55d27bc39496b125aa60fe marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:58,533 - distributed.scheduler - ERROR - Task parse-e34b938029db572383e28308d0e678d9 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:58,536 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54170' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124318.529727')\n",
      "2025-07-10 14:11:58,561 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54196 (pid=24620) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:58,633 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54155 (pid=22316) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:59,011 - distributed.scheduler - ERROR - Task lambda-712bfa3355cb9afb7105347781e3f0cc marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:59,013 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54196' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-312f0aa4f116c8836cb366b50329ee5e'} (stimulus_id='handle-worker-cleanup-1752124319.010756')\n",
      "2025-07-10 14:11:59,242 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54155' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123'} (stimulus_id='handle-worker-cleanup-1752124319.2420292')\n",
      "2025-07-10 14:11:59,355 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54187 (pid=24364) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:59,439 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54185 (pid=22532) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:59,889 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54187' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe', 'parse-7128c5acd13b5041846e91cb149c8f86'} (stimulus_id='handle-worker-cleanup-1752124319.8888514')\n",
      "2025-07-10 14:11:59,896 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54185' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-c300d21e085bcfe9d829512d53ed91cf', 'parse-47217579e3187a294dc169c232fb92aa'} (stimulus_id='handle-worker-cleanup-1752124319.8949227')\n",
      "2025-07-10 14:11:59,963 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:00,698 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:00,716 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:01,288 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:01,307 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:01,939 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54216 (pid=2064) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:04,067 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54208 (pid=10088) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:04,952 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:04,978 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54208' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b4605283a09a7e444a840bd25d255631'} (stimulus_id='handle-worker-cleanup-1752124324.9778435')\n",
      "2025-07-10 14:12:06,685 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:06,947 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54225 (pid=21384) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:07,779 - distributed.scheduler - ERROR - Task parse-3bdbae251d5f99de3fe730b8b74b00a8 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:07,782 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54225' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe'} (stimulus_id='handle-worker-cleanup-1752124327.779773')\n",
      "2025-07-10 14:12:08,641 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54224 (pid=3020) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:09,222 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:09,228 - distributed.scheduler - ERROR - Task parse-7ac421c3f9263d6069f97f744f84d362 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:09,229 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54224' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123'} (stimulus_id='handle-worker-cleanup-1752124329.2271864')\n",
      "2025-07-10 14:12:09,313 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54233 (pid=20248) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:09,802 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54233' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-552d0aff40d81b2ae10bb4554ecb46f4'} (stimulus_id='handle-worker-cleanup-1752124329.8014789')\n",
      "2025-07-10 14:12:10,190 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:10,411 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54243 (pid=24624) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:10,658 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54243' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-c300d21e085bcfe9d829512d53ed91cf'} (stimulus_id='handle-worker-cleanup-1752124330.6575773')\n",
      "2025-07-10 14:12:10,662 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:13,310 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:13,932 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54251 (pid=23572) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:15,202 - distributed.scheduler - ERROR - Task parse-c300d21e085bcfe9d829512d53ed91cf marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:15,205 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54251' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-312f0aa4f116c8836cb366b50329ee5e'} (stimulus_id='handle-worker-cleanup-1752124335.2011523')\n",
      "2025-07-10 14:12:15,218 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54260 (pid=11628) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:15,875 - distributed.scheduler - ERROR - Task parse-c860748d8b3ffb5612067c2ce80abfcb marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:15,881 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54260' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe'} (stimulus_id='handle-worker-cleanup-1752124335.874583')\n",
      "2025-07-10 14:12:16,749 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:17,465 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:18,918 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54275 (pid=17444) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:18,926 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54272 (pid=19756) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:18,932 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54274 (pid=13516) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:20,118 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54274' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123'} (stimulus_id='handle-worker-cleanup-1752124340.1176634')\n",
      "2025-07-10 14:12:20,124 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54275' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-5c8d1072a094f59a0b73bf2f870a5dc7'} (stimulus_id='handle-worker-cleanup-1752124340.123413')\n",
      "2025-07-10 14:12:20,128 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54272' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-552d0aff40d81b2ae10bb4554ecb46f4'} (stimulus_id='handle-worker-cleanup-1752124340.1279602')\n",
      "2025-07-10 14:12:20,135 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54273 (pid=21660) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:20,753 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54273' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-82fffdeaf8077b3a1c93ce9b2e470e39', 'parse-a638d4d932406111249514b782f747d7'} (stimulus_id='handle-worker-cleanup-1752124340.7520225')\n",
      "2025-07-10 14:12:20,958 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54299 (pid=22808) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:21,329 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:21,335 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:21,354 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:21,976 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:22,605 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:26,853 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54292 (pid=15340) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:26,858 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54310 (pid=24148) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:27,500 - distributed.scheduler - ERROR - Task parse-312f0aa4f116c8836cb366b50329ee5e marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:27,502 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54292' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-846372667560771c6f5279ab06086018'} (stimulus_id='handle-worker-cleanup-1752124347.4992182')\n",
      "2025-07-10 14:12:27,511 - distributed.scheduler - ERROR - Task parse-552d0aff40d81b2ae10bb4554ecb46f4 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:27,517 - distributed.scheduler - ERROR - Task parse-2b6f88ff69a64f01ed22761d6964c123 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:29,316 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:29,348 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:31,068 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54325 (pid=22820) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:31,977 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54319 (pid=13800) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:31,991 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54335 (pid=15268) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:32,149 - distributed.scheduler - ERROR - Task parse-be546f7c03be8fa1709e6eb41e20bbbe marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:32,150 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54325' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b4605283a09a7e444a840bd25d255631'} (stimulus_id='handle-worker-cleanup-1752124352.1482377')\n",
      "2025-07-10 14:12:33,021 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54335' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-57272c886034dd9803e752d03bf391f6'} (stimulus_id='handle-worker-cleanup-1752124353.0198858')\n",
      "2025-07-10 14:12:33,072 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54319' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-7128c5acd13b5041846e91cb149c8f86'} (stimulus_id='handle-worker-cleanup-1752124353.0710337')\n",
      "2025-07-10 14:12:34,527 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54346 (pid=132) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:34,603 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:35,433 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54346' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-a638d4d932406111249514b782f747d7'} (stimulus_id='handle-worker-cleanup-1752124355.434059')\n",
      "2025-07-10 14:12:35,440 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:35,462 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:37,603 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:41,301 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54363 (pid=1480) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:43,018 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54363' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-846372667560771c6f5279ab06086018'} (stimulus_id='handle-worker-cleanup-1752124363.016643')\n",
      "2025-07-10 14:12:43,710 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54374 (pid=17436) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:43,985 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54374' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-5c8d1072a094f59a0b73bf2f870a5dc7'} (stimulus_id='handle-worker-cleanup-1752124363.9845462')\n",
      "2025-07-10 14:12:44,291 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54380 (pid=19464) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:44,584 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54380' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b4605283a09a7e444a840bd25d255631', 'parse-82fffdeaf8077b3a1c93ce9b2e470e39'} (stimulus_id='handle-worker-cleanup-1752124364.5840235')\n",
      "2025-07-10 14:12:44,619 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:44,914 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54366 (pid=25568) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:45,121 - distributed.scheduler - ERROR - Task parse-b4605283a09a7e444a840bd25d255631 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:45,123 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54366' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-7128c5acd13b5041846e91cb149c8f86', 'parse-a638d4d932406111249514b782f747d7'} (stimulus_id='handle-worker-cleanup-1752124365.1208863')\n",
      "2025-07-10 14:12:45,167 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:45,516 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:46,018 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54345 (pid=7904) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:46,172 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54345' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-8535ea749a714d7701f8cd5a34a29ebb', 'lambda-6d230cb99c75e91d49852221d3e6b6a9', 'lambda-920454f888bdd2eeea7c6e972229ea6a', 'parse-47217579e3187a294dc169c232fb92aa', 'lambda-83b8ad2a0ed066b7f1a70c664a673e6b', 'lambda-9bde34ee361163fa3d84f570587b1a18', 'lambda-23aad8b835b7b772ddf567f7880413b4'} (stimulus_id='handle-worker-cleanup-1752124366.1717656')\n",
      "2025-07-10 14:12:46,175 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:48,015 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:48,068 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54362 (pid=20120) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:48,765 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54362' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-d94fdef64f1d4144c737260a84a006bb', 'parse-838675ec942f5318655689351ffd515d', 'lambda-c473490af5a870c2d5ced9086303be46', 'lambda-ef06c53b5f0d2c5661eaeb6d7dfa28ce', 'lambda-7b4b1e57c21c2d3576a3f09280debe58', 'lambda-9611703d826d8d557d223d402cb71dc1', 'lambda-be86882405dfc9c93f0b930acc017aba'} (stimulus_id='handle-worker-cleanup-1752124368.7645357')\n",
      "2025-07-10 14:12:49,845 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:52,653 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54413 (pid=23416) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:52,751 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54428 (pid=6440) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:53,261 - distributed.scheduler - ERROR - Task lambda-b44e325b9f72602b0463700108222ec4 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:53,262 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54413' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-82fffdeaf8077b3a1c93ce9b2e470e39'} (stimulus_id='handle-worker-cleanup-1752124373.2608845')\n",
      "2025-07-10 14:12:53,266 - distributed.scheduler - ERROR - Task lambda-a52fbe142a4b2db31ba628ca131d5993 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:53,268 - distributed.scheduler - ERROR - Task lambda-18ab788a60424146b05cbea21eeb5ce6 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:53,271 - distributed.scheduler - ERROR - Task lambda-1329ffe237444b3f6092a78adf5edc8b marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:53,273 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54428' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-47217579e3187a294dc169c232fb92aa'} (stimulus_id='handle-worker-cleanup-1752124373.2662575')\n",
      "2025-07-10 14:12:54,119 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54421 (pid=19844) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:54,860 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:54,876 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54421' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-5c8d1072a094f59a0b73bf2f870a5dc7'} (stimulus_id='handle-worker-cleanup-1752124374.8746572')\n",
      "2025-07-10 14:12:54,880 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:55,763 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54415 (pid=4072) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:56,150 - distributed.scheduler - ERROR - Task lambda-1afe58544ba33556a794b84b3730bfcb marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:56,154 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54415' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-846372667560771c6f5279ab06086018'} (stimulus_id='handle-worker-cleanup-1752124376.149832')\n",
      "2025-07-10 14:12:56,159 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:57,775 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:13:01,135 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54440 (pid=14772) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:13:01,671 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54440' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-9611703d826d8d557d223d402cb71dc1', 'lambda-7b4b1e57c21c2d3576a3f09280debe58', 'lambda-be86882405dfc9c93f0b930acc017aba', 'lambda-af813460571bdbb902487059170e19c2'} (stimulus_id='handle-worker-cleanup-1752124381.6707885')\n",
      "2025-07-10 14:13:01,794 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54456 (pid=25196) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:13:02,821 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54456' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-82fffdeaf8077b3a1c93ce9b2e470e39'} (stimulus_id='handle-worker-cleanup-1752124382.8201945')\n",
      "2025-07-10 14:13:03,245 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54462 (pid=22648) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:13:03,364 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54395 (pid=22488) exceeded 95% memory budget. Restarting...\n"
     ]
    },
    {
     "ename": "KilledWorker",
     "evalue": "Attempted to run task 'parse-f21ed0a8a83a60e0703ffc2cd176ce6c' on 4 different workers, but all those workers died while running it. The last worker that attempt to run the task was tcp://127.0.0.1:54094. Inspecting worker logs is often a good next step to diagnose what went wrong. For more information see https://distributed.dask.org/en/stable/killed.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# 파일 경로\u001b[39;00m\n\u001b[0;32m     11\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../data/통합_train_데이터.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(file_path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\query_compiler_caster.py:1144\u001b[0m, in \u001b[0;36mwrap_function_in_argument_caster.<locals>.f_with_argument_casting\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m# We have to set the global Backend correctly for I/O methods like\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m# read_json() to use the correct backend.\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(Backend\u001b[38;5;241m=\u001b[39mresult_backend):\n\u001b[1;32m-> 1144\u001b[0m     result \u001b[38;5;241m=\u001b[39m f_to_apply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[0;32m   1146\u001b[0m     original_castable,\n\u001b[0;32m   1147\u001b[0m     original_qc,\n\u001b[0;32m   1148\u001b[0m     new_castable,\n\u001b[0;32m   1149\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m inplace_update_trackers:\n\u001b[0;32m   1150\u001b[0m     new_qc \u001b[38;5;241m=\u001b[39m new_castable\u001b[38;5;241m.\u001b[39m_get_query_compiler()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\utils.py:631\u001b[0m, in \u001b[0;36mexpanduser_path_arg.<locals>.decorator.<locals>.wrapped\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patharg, Path):\n\u001b[0;32m    630\u001b[0m         params\u001b[38;5;241m.\u001b[39marguments[argname] \u001b[38;5;241m=\u001b[39m patharg\u001b[38;5;241m.\u001b[39mexpanduser()\n\u001b[1;32m--> 631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\pandas\\io.py:335\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_default:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument is not supported for the fastparquet engine\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m     )\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModinObjects\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m--> 335\u001b[0m     query_compiler\u001b[38;5;241m=\u001b[39mFactoryDispatcher\u001b[38;5;241m.\u001b[39mread_parquet(\n\u001b[0;32m    336\u001b[0m         path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m    337\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    338\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    339\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    340\u001b[0m         use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    341\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    342\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    343\u001b[0m         filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dispatching\\factories\\dispatcher.py:246\u001b[0m, in \u001b[0;36mFactoryDispatcher.read_parquet\u001b[1;34m(cls, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;129m@_inherit_docstrings\u001b[39m(factories\u001b[38;5;241m.\u001b[39mBaseFactory\u001b[38;5;241m.\u001b[39m_read_parquet)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory()\u001b[38;5;241m.\u001b[39m_read_parquet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dispatching\\factories\\factories.py:258\u001b[0m, in \u001b[0;36mBaseFactory._read_parquet\u001b[1;34m(cls, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m    252\u001b[0m     _doc_io_method_template,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m )\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_parquet\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mio_cls\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\io\\file_dispatcher.py:159\u001b[0m, in \u001b[0;36mFileDispatcher.read\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03mRead data according passed `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mpostprocessing work on the resulting query_compiler object.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     query_compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_read(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ModinAssumptionError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    161\u001b[0m     param_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\io\\column_stores\\parquet_dispatcher.py:907\u001b[0m, in \u001b[0;36mParquetDispatcher._read\u001b[1;34m(cls, path, engine, columns, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[0;32m    900\u001b[0m column_names \u001b[38;5;241m=\u001b[39m columns \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01melse\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    901\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    902\u001b[0m     c\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m column_names\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m index_columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mindex_regex\u001b[38;5;241m.\u001b[39mmatch(c)\n\u001b[0;32m    905\u001b[0m ]\n\u001b[1;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_query_compiler(\n\u001b[0;32m    908\u001b[0m     dataset, columns, index_columns, dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    909\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\io\\column_stores\\parquet_dispatcher.py:775\u001b[0m, in \u001b[0;36mParquetDispatcher.build_query_compiler\u001b[1;34m(cls, dataset, columns, index_columns, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m remote_parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_partition(partition_ids, column_widths)\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(partition_ids) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     row_lengths \u001b[38;5;241m=\u001b[39m [part\u001b[38;5;241m.\u001b[39mlength() \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m remote_parts\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     row_lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dask\\implementations\\pandas_on_dask\\partitioning\\partition.py:272\u001b[0m, in \u001b[0;36mPandasOnDaskDataframePartition.length\u001b[1;34m(self, materialize)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39m_data\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache, Future) \u001b[38;5;129;01mand\u001b[39;00m materialize:\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_wrapper\u001b[38;5;241m.\u001b[39mmaterialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dask\\common\\engine_wrapper.py:160\u001b[0m, in \u001b[0;36mDaskWrapper.materialize\u001b[1;34m(cls, future)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mMaterialize data matching `future` object.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    An object(s) from the distributed memory.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m client \u001b[38;5;241m=\u001b[39m get_dask_client()\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client\u001b[38;5;241m.\u001b[39mgather(future)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\distributed\\client.py:2553\u001b[0m, in \u001b[0;36mClient.gather\u001b[1;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[0;32m   2550\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2552\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m-> 2553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync(\n\u001b[0;32m   2554\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather,\n\u001b[0;32m   2555\u001b[0m         futures,\n\u001b[0;32m   2556\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   2557\u001b[0m         direct\u001b[38;5;241m=\u001b[39mdirect,\n\u001b[0;32m   2558\u001b[0m         local_worker\u001b[38;5;241m=\u001b[39mlocal_worker,\n\u001b[0;32m   2559\u001b[0m         asynchronous\u001b[38;5;241m=\u001b[39masynchronous,\n\u001b[0;32m   2560\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\distributed\\client.py:2414\u001b[0m, in \u001b[0;36mClient._gather\u001b[1;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[0;32m   2412\u001b[0m     exception \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mexception\n\u001b[0;32m   2413\u001b[0m     traceback \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mtraceback\n\u001b[1;32m-> 2414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m   2415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2416\u001b[0m     bad_keys\u001b[38;5;241m.\u001b[39madd(key)\n",
      "\u001b[1;31mKilledWorker\u001b[0m: Attempted to run task 'parse-f21ed0a8a83a60e0703ffc2cd176ce6c' on 4 different workers, but all those workers died while running it. The last worker that attempt to run the task was tcp://127.0.0.1:54094. Inspecting worker logs is often a good next step to diagnose what went wrong. For more information see https://distributed.dask.org/en/stable/killed.html."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 14:13:05,057 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54462' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-5c8d1072a094f59a0b73bf2f870a5dc7'} (stimulus_id='handle-worker-cleanup-1752124385.056405')\n",
      "2025-07-10 14:13:05,064 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54395' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-bbc1b27b64c98b3c9c97a2650baf8e98', 'lambda-5f36c92bf874021df92202d3369baf42', 'lambda-3947224b284d23576fb31e830e213aa4', 'lambda-23aad8b835b7b772ddf567f7880413b4', 'lambda-d07a7b46d197e6ccc064770b29af67a9', 'lambda-cf61cabc2a40762108f101346a3d1ed7', 'lambda-6d230cb99c75e91d49852221d3e6b6a9', 'lambda-284c0114ef9b23b01851301e8613ed0f', 'lambda-8b51a00ed557f244acbd662fd178f37e', 'lambda-98fd10a58ba1722b3e4b849498bf69bc', 'parse-9f3fa5e57bee07e83e19da82dedd87bb', 'parse-4a2772953aa0b63b6ce9337f14548e8c', 'parse-7128c5acd13b5041846e91cb149c8f86', 'lambda-469ca839151bd1fd5893c86c27648cde'} (stimulus_id='handle-worker-cleanup-1752124385.0636818')\n",
      "2025-07-10 14:13:05,287 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54448 (pid=6836) exceeded 95% memory budget. Restarting...\n"
     ]
    }
   ],
   "source": [
    "# Modin 벡엔드를 ray로 강제 설정\n",
    "\n",
    "\n",
    "# 이후 Modin 코드 실행\n",
    "import modin.pandas as pd\n",
    "df = pd.DataFrame({\"a\": [1,2,3]})\n",
    "print(df)\n",
    "\n",
    "\n",
    "# 파일 경로\n",
    "file_path = \"../../../data/통합_train_데이터.parquet\"\n",
    "df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3904bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(selected_cols))         \n",
    "print(type(selected_cols[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9337062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_categorical_columns(df, verbose=True):\n",
    "    \"\"\"\n",
    "    미리 정의된 매핑 기준에 따라 범주형 컬럼들을 수치형으로 변환합니다.\n",
    "    처리 컬럼: 거주시도명, 연회비발생카드수_B0M, 한도증액횟수_R12M, 이용금액대,\n",
    "              할인건수_R3M, 할인건수_B0M, 방문횟수_PC_R6M, 방문횟수_앱_R6M, 방문일수_PC_R6M\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 거주시도명 → 수도권 여부\n",
    "    capital_area = ['서울특별시', '경기도', '인천광역시']\n",
    "    if '거주시도명' in df.columns:\n",
    "        df['거주시도_수도권여부'] = df['거주시도명'].apply(lambda x: 1 if x in capital_area else 0)\n",
    "        df.drop(columns=['거주시도명'], inplace=True)\n",
    "        if verbose: print(\"[거주시도명] → 수도권 여부 인코딩 완료\")\n",
    "\n",
    "    # 2. 연회비발생카드수_B0M\n",
    "    mapping = {\"0개\": 0, \"1개이상\": 1}\n",
    "    if '연회비발생카드수_B0M' in df.columns:\n",
    "        df['연회비발생카드수_B0M'] = df['연회비발생카드수_B0M'].map(mapping).astype(int)\n",
    "        if verbose: print(\"[연회비발생카드수_B0M] 인코딩 완료\")\n",
    "\n",
    "    # 3. 한도증액횟수_R12M\n",
    "    mapping = {\"0회\": 0, \"1회이상\": 1}\n",
    "    if '한도증액횟수_R12M' in df.columns:\n",
    "        df['한도증액횟수_R12M'] = df['한도증액횟수_R12M'].map(mapping).astype(int)\n",
    "        if verbose: print(\"[한도증액횟수_R12M] 인코딩 완료\")\n",
    "\n",
    "    # 4. 이용금액대 (중간값 기준: 만원 단위)\n",
    "    mapping = {\n",
    "        \"09.미사용\": 0,\n",
    "        \"05.10만원-\": 5,\n",
    "        \"04.10만원+\": 20,\n",
    "        \"03.30만원+\": 40,\n",
    "        \"02.50만원+\": 75,\n",
    "        \"01.100만원+\": 150\n",
    "    }\n",
    "    if '이용금액대' in df.columns:\n",
    "        df['이용금액대'] = df['이용금액대'].map(mapping)\n",
    "        if verbose: print(\"[이용금액대] 중간값 인코딩 완료\")\n",
    "\n",
    "    # 5. 할인건수 인코딩\n",
    "    discount_map = {\n",
    "        \"1회 이상\": 1,\n",
    "        \"10회 이상\": 10,\n",
    "        \"20회 이상\": 20,\n",
    "        \"30회 이상\": 30,\n",
    "        \"40회 이상\": 40\n",
    "    }\n",
    "    for col in ['할인건수_R3M', '할인건수_B0M']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(discount_map).astype(int)\n",
    "            if verbose: print(f\"[{col}] 인코딩 완료\")\n",
    "\n",
    "    # 6. 방문횟수 및 방문일수 인코딩\n",
    "    visit_map = {\n",
    "        \"1회 이상\": 1,\n",
    "        \"10회 이상\": 10,\n",
    "        \"20회 이상\": 20,\n",
    "        \"30회 이상\": 30,\n",
    "        \"40회 이상\": 40,\n",
    "        \"50회 이상\": 50,\n",
    "        \"60회 이상\": 60,\n",
    "        \"70회 이상\": 70,\n",
    "        \"80회 이상\": 80\n",
    "    }\n",
    "\n",
    "    visit_cols = ['방문횟수_PC_R6M', '방문횟수_앱_R6M', '방문일수_PC_R6M']\n",
    "    for col in visit_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(visit_map).astype(int)\n",
    "            if verbose: print(f\"[{col}] 인코딩 완료\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c972e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1. 데이터 불러오기\n",
    "df = pd.read_parquet(\"../../../data/통합_train_데이터.parquet\")\n",
    "\n",
    "# 2. 피처 및 타겟 분리\n",
    "X = df[pca_cols].copy() \n",
    "y = df[\"Segment\"]\n",
    "\n",
    "X = X.loc[:, ~X.columns.duplicated()] #중복제거\n",
    "\n",
    "# 3. 범주형 인코딩\n",
    "df = map_categorical_columns(df)\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# 4. 결측치 처리\n",
    "X = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 스케일링 (DataFrame 형태 유지)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# 라벨인코딩\n",
    "le_y = LabelEncoder()\n",
    "y_encoded = le_y.fit_transform(y)\n",
    "\n",
    "# 6. train-validation 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "# CPU 모델 사용\n",
    "xgb_model = XGBClassifier(\n",
    "    tree_method='hist',         # GPU 대신 CPU 전용 히스토그램 기반\n",
    "    predictor='auto',           # 자동 설정 (CPU에 맞게)\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# 8. 학습\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 9. 예측 및 평가\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b20f2-6c05-4a34-b874-49ce16024364",
   "metadata": {},
   "source": [
    "### 전환 후보군 대상이 되는 피처 탐색\n",
    "- 예측 확률이 0.6 이상 되는 피처를 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6935afb-cb76-4eee-a396-15d09c3005a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import modin.pandas as pd\n",
    "\n",
    "# 10. 예측 확률 계산\n",
    "y_proba = xgb_model.predict_proba(X_val)  # 클래스별 확률 반환\n",
    "\n",
    "# 11. 가장 높은 확률의 클래스 선택\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "\n",
    "# 12. 확률이 0.6 이상인 고객만 추출\n",
    "threshold = 0.6\n",
    "high_confidence_mask = np.max(y_proba, axis=1) >= threshold\n",
    "\n",
    "# 13. 결과 정리\n",
    "result_df = X_val.copy()\n",
    "result_df['real_segment'] = le_y.inverse_transform(y_val)\n",
    "result_df['predicted_segment'] = le_y.inverse_transform(y_pred)\n",
    "result_df['predicted_prob'] = np.max(y_proba, axis=1)\n",
    "\n",
    "# 14. 확률이 0.6 이상인 전환 후보군만 추출\n",
    "candidate_df = result_df[high_confidence_mask]\n",
    "\n",
    "# 15. 상위 10개 미리보기\n",
    "print(\"✅ 확률 0.6 이상인 전환 후보군:\")\n",
    "print(candidate_df[['real_segment', 'predicted_segment', 'predicted_prob']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ac489-d2b0-4df1-9d55-49cdd7e5dd3f",
   "metadata": {},
   "source": [
    "### 전환 경계선에 있는 고객\n",
    "- 0.5 ~ 0.74 사이에 있는 고객을 전환 후보군으로 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ad851-59b9-44b6-9ff0-0c2c1f0e2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 확률이 0.5 ~ 0.74 사이이면서, 실제와 예측이 다른 경우만!\n",
    "unstable_candidates = result_df[\n",
    "    (result_df['predicted_prob'] >= 0.5) &\n",
    "    (result_df['predicted_prob'] <= 0.74) &\n",
    "    (result_df['real_segment'] != result_df['predicted_segment'])\n",
    "]\n",
    "\n",
    "print(unstable_candidates[['real_segment', 'predicted_segment', 'predicted_prob']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d45538-a49d-4726-a2e6-a3ab47ffa17d",
   "metadata": {},
   "source": [
    "### 없다니??\n",
    "\n",
    "#### 현재 조건\n",
    "- 예측 확률이 0.5 이상 0.74 이하인 사람이면서\n",
    "- 실제 세그먼트랑 예측 세그먼트가 다른 사람\n",
    "\n",
    "즉!! 이 두 조건을 모두 만족하는 사람이 없다는 뜻\n",
    "\n",
    "## 원인은?\n",
    "### ✅ 왜 없을 수도 있냐?\n",
    "#### 모델이 너무 확신하고 있어서\n",
    "→ 대부분의 예측 확률이 0.9 이상이야 (실제로 출력된 거 보면 거의 다 0.999...)\n",
    "\n",
    "#### 데이터가 균형 잡혀 있어서 예측이 단단할 수 있음\n",
    "→ 그래서 전환 “경계선”에 애매하게 걸친 사람이 안 보이는 거야\n",
    "\n",
    "#### 데이터셋 사이즈가 작거나 test셋에 그런 케이스가 없는 것일 수도 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447a0b9-cdd9-4677-af46-260626e03fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확률을 더 넓게: 0.4 ~ 0.8 사이\n",
    "unstable_candidates = result_df[\n",
    "    (result_df['predicted_prob'] >= 0.4) &\n",
    "    (result_df['predicted_prob'] <= 0.8) &\n",
    "    (result_df['real_segment'] != result_df['predicted_segment'])\n",
    "]\n",
    "\n",
    "print(unstable_candidates[['real_segment', 'predicted_segment', 'predicted_prob']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90476cf5-4e11-4928-8af5-d9f0d1df8557",
   "metadata": {},
   "source": [
    "### 실제 학습된 모델의 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e151197-e7f3-49fd-9dc4-8e0ab5ae70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 경고 뜨지 않게 설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 그래프 설정\n",
    "sns.set()\n",
    "\n",
    "# 그래프 기본 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 결측치 시각화를 위한 라이브러리\n",
    "import missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfc1ec-e601-4d43-968c-b08dfbf12108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(result_df['predicted_prob'], bins=30, kde=True)\n",
    "plt.axvline(0.6, color='red', linestyle='--', label='0.6 threshold')\n",
    "plt.title(\"📊 전체 예측 확률 분포\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952fbfc-332b-4e77-a5b4-f801d2cedb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_proba[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b4b25-128d-4693-b72c-847c75e55bff",
   "metadata": {},
   "source": [
    "## 🔍 예측 확률 분석 결과 정리\n",
    "\n",
    "### ✅ 예측 확률 분포 해석\n",
    "- 대부분의 예측 확률이 `0.999 이상`에 몰려 있음\n",
    "- 모델이 예측한 세그먼트에 대해 **거의 100% 확신을 가지고 있음**\n",
    "- 따라서, 전환 가능성이 있는 **경계선 고객 (예: 0.5 ~ 0.74)** 은 거의 없음\n",
    "\n",
    "---\n",
    "\n",
    "### ⚠️ 문제점 요약\n",
    "\n",
    "| 항목 | 설명 |\n",
    "|------|------|\n",
    "| 과확신 (Overconfidence) | 모델이 모든 예측에 대해 너무 확신함 (확률 분포가 한쪽으로 치우침) |\n",
    "| 전환 후보 부족 | `real_segment ≠ predicted_segment` 이면서 `확률이 애매한 고객`이 거의 없음 |\n",
    "| 해석 어려움 | SHAP 없이 예측 결과만으로는 KPI 분석이나 전환 인사이트 도출이 어려움 |\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 원인 추정\n",
    "\n",
    "1. **과적합**: validation data까지 외운 듯한 모델 동작\n",
    "2. **클래스 불균형**: 특정 세그먼트가 많아서 그쪽으로 쏠림\n",
    "3. **강한 피처**: 일부 피처가 세그먼트를 거의 결정할 정도로 강력\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 다음 단계 제안\n",
    "\n",
    "- SHAP 분석으로 모델이 **왜 확신하고 있는지** 피처 기반으로 해석\n",
    "- 다른 모델(Logistic, LightGBM 등)과 비교\n",
    "- 예측 데이터셋을 진짜 운영 고객 데이터로 교체해보기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099fee94-b454-4b72-af53-7c5ad1a60805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# 1. TreeExplainer 정의\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "\n",
    "# 2. validation 데이터에 대한 shap 값 계산\n",
    "shap_values = explainer(X_val)\n",
    "\n",
    "# 3. SHAP summary plot (feature 중요도 전체 시각화)\n",
    "shap.summary_plot(shap_values, X_val, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34b9486-a6c3-4e31-be86-10ee5bd5bfc1",
   "metadata": {},
   "source": [
    "### 🎯 SHAP 분석 기반 KPI 후보 지표\n",
    "\n",
    "1. **정상청구원금_B5M**  \n",
    "   - 최근 5개월 동안 청구된 정상 원금 총액  \n",
    "   - 고객의 상환 규모 또는 부채 수준을 보여주는 주요 지표\n",
    "\n",
    "2. **이용금액_R3M_신용체크**  \n",
    "   - 최근 3개월간 신용 및 체크카드 이용액  \n",
    "   - 카드 사용 패턴과 소비 성향 반영\n",
    "\n",
    "3. **청구금액_R6M**  \n",
    "   - 최근 6개월 누적 청구 금액  \n",
    "   - 고액 청구 고객 → 상향 가능성 판단 가능\n",
    "\n",
    "4. **카드론이용금액_누적 / 평잔_할부_3M** 등도 뒤따라 등장  \n",
    "   - 리볼빙·할부 습관은 리스크 요인 or 등급 유지 요인으로 작용 가능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e02496-db1d-4587-bc64-2acf17ae47e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
