{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94eddf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ PC1~PC5ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ì¤‘ìš”í•œ ë³€ìˆ˜:\n",
    "pca_cols = [\n",
    "    'CAì´ìžìœ¨_í• ì¸ì „', 'CLì´ìžìœ¨_í• ì¸ì „', 'RV_í‰ê· ìž”ì•¡_R3M', 'RVì¼ì‹œë¶ˆì´ìžìœ¨_í• ì¸ì „', 'RVìµœì†Œê²°ì œë¹„ìœ¨', 'RVí˜„ê¸ˆì„œë¹„ìŠ¤ì´ìžìœ¨_í• ì¸ì „', \n",
    "    'ë°©ë¬¸ì›”ìˆ˜_ì•±_R6M', 'ë°©ë¬¸ì¼ìˆ˜_ì•±_B0M', 'ë°©ë¬¸ì¼ìˆ˜_ì•±_R6M', 'ë°©ë¬¸íšŸìˆ˜_ì•±_B0M', 'ë°©ë¬¸í›„ê²½ê³¼ì›”_ì•±_R6M', \n",
    "    'ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©', 'ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©ì²´í¬', 'ì´ìš©ê¸ˆì•¡_ì¼ì‹œë¶ˆ_B0M', 'ì´ìš©ê¸ˆì•¡ëŒ€', \n",
    "    'ì¼ì‹œë¶ˆONLYì „í™˜ê°€ëŠ¥ì—¬ë¶€', \n",
    "    'ìž”ì•¡_ë¦¬ë³¼ë¹™ì¼ì‹œë¶ˆì´ì›”_B0M', 'ìž”ì•¡_ì¼ì‹œë¶ˆ_B0M', 'ìž”ì•¡_ì¼ì‹œë¶ˆ_B1M', 'ìž”ì•¡_ì¼ì‹œë¶ˆ_B2M', 'ìž”ì•¡_ì¹´ë“œë¡ _B0M', 'ìž”ì•¡_ì¹´ë“œë¡ _B1M', 'ìž”ì•¡_ì¹´ë“œë¡ _B2M', 'ìž”ì•¡_ì¹´ë“œë¡ _B3M', 'ìž”ì•¡_ì¹´ë“œë¡ _B4M', 'ìž”ì•¡_ì¹´ë“œë¡ _B5M', \n",
    "    'ì •ìƒì²­êµ¬ì›ê¸ˆ_B0M', 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B2M', 'ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M', \n",
    "    'ì²­êµ¬ê¸ˆì•¡_B0', 'ì²­êµ¬ê¸ˆì•¡_R3M', 'ì²­êµ¬ê¸ˆì•¡_R6M', 'ìµœì¢…ì¹´ë“œë¡ _ëŒ€ì¶œê¸ˆì•¡', 'ì¹´ë“œë¡ ì´ìš©ê¸ˆì•¡_ëˆ„ì ', 'í‰ìž”_RVì¼ì‹œë¶ˆ_3M', 'í‰ìž”_RVì¼ì‹œë¶ˆ_6M', 'í‰ìž”_ì¼ì‹œë¶ˆ_3M', 'í‰ìž”_ì¼ì‹œë¶ˆ_6M', \n",
    "    'í‰ìž”_ì¹´ë“œë¡ _3M', 'í‰ìž”_ì¹´ë“œë¡ _6M', 'í‰ìž”_í• ë¶€_3M', 'í™ˆíŽ˜ì´ì§€_ê¸ˆìœµê±´ìˆ˜_R3M', 'í™ˆíŽ˜ì´ì§€_ê¸ˆìœµê±´ìˆ˜_R6M', 'í™ˆíŽ˜ì´ì§€_ì„ ê²°ì œê±´ìˆ˜_R3M', 'í™ˆíŽ˜ì´ì§€_ì„ ê²°ì œê±´ìˆ˜_R6M'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544e934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_cols = [\"ID\",\"Segment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c8e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = pca_cols + base_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9356e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a\n",
      "0  1\n",
      "1  2\n",
      "2  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 14:11:07,765 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53975 (pid=17420) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:10,276 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53971 (pid=18892) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:10,416 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:10,684 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53969 (pid=6272) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:11,363 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53969' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123', 'lambda-e96255760db5f9bd771cb86b70bd1eb2'} (stimulus_id='handle-worker-cleanup-1752124271.3626504')\n",
      "2025-07-10 14:11:11,730 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53967 (pid=18604) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:12,165 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53967' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-f21ed0a8a83a60e0703ffc2cd176ce6c'} (stimulus_id='handle-worker-cleanup-1752124272.1654265')\n",
      "2025-07-10 14:11:12,167 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:53967' caused the cluster to lose scattered data, which can't be recovered: {'DataFrame-19cec8dca68749e79ac1ea7ea87acc91'} (stimulus_id='handle-worker-cleanup-1752124272.1654265')\n",
      "2025-07-10 14:11:12,618 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53979 (pid=13244) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:12,677 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53970 (pid=19132) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:12,923 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53970' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-f40b8553ae0413f2b6f4a7a6e84f9015'} (stimulus_id='handle-worker-cleanup-1752124272.9228415')\n",
      "2025-07-10 14:11:13,296 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:13,580 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:14,898 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:14,935 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53968 (pid=24580) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:15,281 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53968' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124275.2792547')\n",
      "2025-07-10 14:11:15,283 - distributed.scheduler - ERROR - Removing worker 'tcp://127.0.0.1:53968' caused the cluster to lose scattered data, which can't be recovered: {'function-1cd8e093de65c88a610ccbb30fa7918c'} (stimulus_id='handle-worker-cleanup-1752124275.2792547')\n",
      "2025-07-10 14:11:16,074 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:16,225 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53982 (pid=18348) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:16,519 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53982' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-e34b938029db572383e28308d0e678d9'} (stimulus_id='handle-worker-cleanup-1752124276.5186963')\n",
      "2025-07-10 14:11:16,524 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:17,546 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53972 (pid=2800) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:18,170 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53972' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-fe35ad8d0e84a59a26425794e14b097b'} (stimulus_id='handle-worker-cleanup-1752124278.169662')\n",
      "2025-07-10 14:11:18,953 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:19,847 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:21,111 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:21,349 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53977 (pid=10272) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:21,352 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53976 (pid=4784) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:21,951 - distributed.scheduler - ERROR - Task parse-f278a817eaf6a8e4f8687977c860ea17 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:21,952 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53977' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-517eaebe6744c735eb2f46a2c64c1464'} (stimulus_id='handle-worker-cleanup-1752124281.9506702')\n",
      "2025-07-10 14:11:21,964 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:53976' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b6c24d0bbcbce437e36f3f63f8d33f42'} (stimulus_id='handle-worker-cleanup-1752124281.9637914')\n",
      "2025-07-10 14:11:22,366 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:53978 (pid=18436) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:23,514 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54039 (pid=6772) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:24,267 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54039' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124284.266864')\n",
      "2025-07-10 14:11:24,270 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:24,281 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:25,571 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:25,840 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:26,119 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54053 (pid=24544) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:26,759 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54053' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-7ac421c3f9263d6069f97f744f84d362'} (stimulus_id='handle-worker-cleanup-1752124286.7584589')\n",
      "2025-07-10 14:11:27,732 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54052 (pid=10448) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:28,228 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54052' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe', 'parse-c521d4f02a4118847b50f69e7209dd90'} (stimulus_id='handle-worker-cleanup-1752124288.2273602')\n",
      "2025-07-10 14:11:28,247 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:28,951 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54063 (pid=14608) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:29,414 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:29,422 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54063' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b6c24d0bbcbce437e36f3f63f8d33f42'} (stimulus_id='handle-worker-cleanup-1752124289.4211466')\n",
      "2025-07-10 14:11:30,404 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54070 (pid=22924) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:31,473 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:31,490 - distributed.scheduler - ERROR - Task parse-82f0fc78267c899855fabc8dcfb170a2 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:31,493 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54070' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-e34b938029db572383e28308d0e678d9'} (stimulus_id='handle-worker-cleanup-1752124291.4881847')\n",
      "2025-07-10 14:11:31,502 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54073 (pid=23684) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:32,352 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54073' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-c860748d8b3ffb5612067c2ce80abfcb'} (stimulus_id='handle-worker-cleanup-1752124292.3514655')\n",
      "2025-07-10 14:11:32,964 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:33,169 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54088 (pid=23564) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:33,515 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:33,533 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54094 (pid=23096) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:33,858 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54088' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124293.8579204')\n",
      "2025-07-10 14:11:33,866 - distributed.scheduler - ERROR - Task parse-f21ed0a8a83a60e0703ffc2cd176ce6c marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:35,340 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54100 (pid=24240) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:35,914 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54100' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b6c24d0bbcbce437e36f3f63f8d33f42', 'parse-7ac421c3f9263d6069f97f744f84d362'} (stimulus_id='handle-worker-cleanup-1752124295.9145947')\n",
      "2025-07-10 14:11:35,936 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:35,943 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:37,511 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:39,926 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54117 (pid=23144) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:41,034 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54117' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-6106482fed2984161e8f34d054b1d67d'} (stimulus_id='handle-worker-cleanup-1752124301.0327654')\n",
      "2025-07-10 14:11:41,842 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54137 (pid=10804) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:42,262 - distributed.scheduler - ERROR - Task parse-b6c24d0bbcbce437e36f3f63f8d33f42 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:42,264 - distributed.scheduler - ERROR - Task parse-c521d4f02a4118847b50f69e7209dd90 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:42,276 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54125 (pid=15596) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:43,055 - distributed.scheduler - ERROR - Task lambda-cd8131de10e0edaec093714fa3d7ec41 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:43,064 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54125' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124303.0524733')\n",
      "2025-07-10 14:11:43,179 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:43,271 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54114 (pid=24148) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:45,302 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54114' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123'} (stimulus_id='handle-worker-cleanup-1752124305.3022122')\n",
      "2025-07-10 14:11:45,310 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:46,378 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54128 (pid=23184) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:46,846 - distributed.scheduler - ERROR - Task parse-6106482fed2984161e8f34d054b1d67d marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:46,853 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54128' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe', 'parse-846372667560771c6f5279ab06086018'} (stimulus_id='handle-worker-cleanup-1752124306.8450594')\n",
      "2025-07-10 14:11:47,031 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:47,780 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:47,806 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54145 (pid=24760) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:48,689 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:49,768 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54145' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-312f0aa4f116c8836cb366b50329ee5e', 'parse-7ac421c3f9263d6069f97f744f84d362'} (stimulus_id='nanny-close-1752124308.675183')\n",
      "2025-07-10 14:11:50,978 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:51,066 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54166 (pid=10248) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:52,230 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54166' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-c860748d8b3ffb5612067c2ce80abfcb'} (stimulus_id='handle-worker-cleanup-1752124312.229281')\n",
      "2025-07-10 14:11:55,421 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:11:57,443 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54170 (pid=5624) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:58,531 - distributed.scheduler - ERROR - Task lambda-2d4ac82d2e55d27bc39496b125aa60fe marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:58,533 - distributed.scheduler - ERROR - Task parse-e34b938029db572383e28308d0e678d9 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:58,536 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54170' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-3bdbae251d5f99de3fe730b8b74b00a8'} (stimulus_id='handle-worker-cleanup-1752124318.529727')\n",
      "2025-07-10 14:11:58,561 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54196 (pid=24620) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:58,633 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54155 (pid=22316) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:59,011 - distributed.scheduler - ERROR - Task lambda-712bfa3355cb9afb7105347781e3f0cc marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:11:59,013 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54196' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-312f0aa4f116c8836cb366b50329ee5e'} (stimulus_id='handle-worker-cleanup-1752124319.010756')\n",
      "2025-07-10 14:11:59,242 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54155' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123'} (stimulus_id='handle-worker-cleanup-1752124319.2420292')\n",
      "2025-07-10 14:11:59,355 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54187 (pid=24364) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:59,439 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54185 (pid=22532) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:11:59,889 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54187' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe', 'parse-7128c5acd13b5041846e91cb149c8f86'} (stimulus_id='handle-worker-cleanup-1752124319.8888514')\n",
      "2025-07-10 14:11:59,896 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54185' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-c300d21e085bcfe9d829512d53ed91cf', 'parse-47217579e3187a294dc169c232fb92aa'} (stimulus_id='handle-worker-cleanup-1752124319.8949227')\n",
      "2025-07-10 14:11:59,963 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:00,698 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:00,716 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:01,288 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:01,307 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:01,939 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54216 (pid=2064) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:04,067 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54208 (pid=10088) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:04,952 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:04,978 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54208' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b4605283a09a7e444a840bd25d255631'} (stimulus_id='handle-worker-cleanup-1752124324.9778435')\n",
      "2025-07-10 14:12:06,685 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:06,947 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54225 (pid=21384) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:07,779 - distributed.scheduler - ERROR - Task parse-3bdbae251d5f99de3fe730b8b74b00a8 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:07,782 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54225' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe'} (stimulus_id='handle-worker-cleanup-1752124327.779773')\n",
      "2025-07-10 14:12:08,641 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54224 (pid=3020) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:09,222 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:09,228 - distributed.scheduler - ERROR - Task parse-7ac421c3f9263d6069f97f744f84d362 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:09,229 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54224' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123'} (stimulus_id='handle-worker-cleanup-1752124329.2271864')\n",
      "2025-07-10 14:12:09,313 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54233 (pid=20248) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:09,802 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54233' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-552d0aff40d81b2ae10bb4554ecb46f4'} (stimulus_id='handle-worker-cleanup-1752124329.8014789')\n",
      "2025-07-10 14:12:10,190 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:10,411 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54243 (pid=24624) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:10,658 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54243' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-c300d21e085bcfe9d829512d53ed91cf'} (stimulus_id='handle-worker-cleanup-1752124330.6575773')\n",
      "2025-07-10 14:12:10,662 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:13,310 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:13,932 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54251 (pid=23572) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:15,202 - distributed.scheduler - ERROR - Task parse-c300d21e085bcfe9d829512d53ed91cf marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:15,205 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54251' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-312f0aa4f116c8836cb366b50329ee5e'} (stimulus_id='handle-worker-cleanup-1752124335.2011523')\n",
      "2025-07-10 14:12:15,218 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54260 (pid=11628) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:15,875 - distributed.scheduler - ERROR - Task parse-c860748d8b3ffb5612067c2ce80abfcb marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:15,881 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54260' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-be546f7c03be8fa1709e6eb41e20bbbe'} (stimulus_id='handle-worker-cleanup-1752124335.874583')\n",
      "2025-07-10 14:12:16,749 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:17,465 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:18,918 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54275 (pid=17444) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:18,926 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54272 (pid=19756) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:18,932 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54274 (pid=13516) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:20,118 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54274' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-2b6f88ff69a64f01ed22761d6964c123'} (stimulus_id='handle-worker-cleanup-1752124340.1176634')\n",
      "2025-07-10 14:12:20,124 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54275' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-5c8d1072a094f59a0b73bf2f870a5dc7'} (stimulus_id='handle-worker-cleanup-1752124340.123413')\n",
      "2025-07-10 14:12:20,128 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54272' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-552d0aff40d81b2ae10bb4554ecb46f4'} (stimulus_id='handle-worker-cleanup-1752124340.1279602')\n",
      "2025-07-10 14:12:20,135 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54273 (pid=21660) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:20,753 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54273' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-82fffdeaf8077b3a1c93ce9b2e470e39', 'parse-a638d4d932406111249514b782f747d7'} (stimulus_id='handle-worker-cleanup-1752124340.7520225')\n",
      "2025-07-10 14:12:20,958 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54299 (pid=22808) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:21,329 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:21,335 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:21,354 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:21,976 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:22,605 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:26,853 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54292 (pid=15340) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:26,858 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54310 (pid=24148) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:27,500 - distributed.scheduler - ERROR - Task parse-312f0aa4f116c8836cb366b50329ee5e marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:27,502 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54292' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-846372667560771c6f5279ab06086018'} (stimulus_id='handle-worker-cleanup-1752124347.4992182')\n",
      "2025-07-10 14:12:27,511 - distributed.scheduler - ERROR - Task parse-552d0aff40d81b2ae10bb4554ecb46f4 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:27,517 - distributed.scheduler - ERROR - Task parse-2b6f88ff69a64f01ed22761d6964c123 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:29,316 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:29,348 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:31,068 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54325 (pid=22820) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:31,977 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54319 (pid=13800) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:31,991 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54335 (pid=15268) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:32,149 - distributed.scheduler - ERROR - Task parse-be546f7c03be8fa1709e6eb41e20bbbe marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:32,150 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54325' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b4605283a09a7e444a840bd25d255631'} (stimulus_id='handle-worker-cleanup-1752124352.1482377')\n",
      "2025-07-10 14:12:33,021 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54335' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-57272c886034dd9803e752d03bf391f6'} (stimulus_id='handle-worker-cleanup-1752124353.0198858')\n",
      "2025-07-10 14:12:33,072 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54319' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-7128c5acd13b5041846e91cb149c8f86'} (stimulus_id='handle-worker-cleanup-1752124353.0710337')\n",
      "2025-07-10 14:12:34,527 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54346 (pid=132) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:34,603 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:35,433 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54346' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-a638d4d932406111249514b782f747d7'} (stimulus_id='handle-worker-cleanup-1752124355.434059')\n",
      "2025-07-10 14:12:35,440 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:35,462 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:37,603 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:41,301 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54363 (pid=1480) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:43,018 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54363' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-846372667560771c6f5279ab06086018'} (stimulus_id='handle-worker-cleanup-1752124363.016643')\n",
      "2025-07-10 14:12:43,710 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54374 (pid=17436) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:43,985 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54374' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-5c8d1072a094f59a0b73bf2f870a5dc7'} (stimulus_id='handle-worker-cleanup-1752124363.9845462')\n",
      "2025-07-10 14:12:44,291 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54380 (pid=19464) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:44,584 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54380' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-b4605283a09a7e444a840bd25d255631', 'parse-82fffdeaf8077b3a1c93ce9b2e470e39'} (stimulus_id='handle-worker-cleanup-1752124364.5840235')\n",
      "2025-07-10 14:12:44,619 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:44,914 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54366 (pid=25568) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:45,121 - distributed.scheduler - ERROR - Task parse-b4605283a09a7e444a840bd25d255631 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:45,123 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54366' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-7128c5acd13b5041846e91cb149c8f86', 'parse-a638d4d932406111249514b782f747d7'} (stimulus_id='handle-worker-cleanup-1752124365.1208863')\n",
      "2025-07-10 14:12:45,167 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:45,516 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:46,018 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54345 (pid=7904) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:46,172 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54345' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-8535ea749a714d7701f8cd5a34a29ebb', 'lambda-6d230cb99c75e91d49852221d3e6b6a9', 'lambda-920454f888bdd2eeea7c6e972229ea6a', 'parse-47217579e3187a294dc169c232fb92aa', 'lambda-83b8ad2a0ed066b7f1a70c664a673e6b', 'lambda-9bde34ee361163fa3d84f570587b1a18', 'lambda-23aad8b835b7b772ddf567f7880413b4'} (stimulus_id='handle-worker-cleanup-1752124366.1717656')\n",
      "2025-07-10 14:12:46,175 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:48,015 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:48,068 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54362 (pid=20120) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:48,765 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54362' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-d94fdef64f1d4144c737260a84a006bb', 'parse-838675ec942f5318655689351ffd515d', 'lambda-c473490af5a870c2d5ced9086303be46', 'lambda-ef06c53b5f0d2c5661eaeb6d7dfa28ce', 'lambda-7b4b1e57c21c2d3576a3f09280debe58', 'lambda-9611703d826d8d557d223d402cb71dc1', 'lambda-be86882405dfc9c93f0b930acc017aba'} (stimulus_id='handle-worker-cleanup-1752124368.7645357')\n",
      "2025-07-10 14:12:49,845 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:52,653 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54413 (pid=23416) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:52,751 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54428 (pid=6440) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:53,261 - distributed.scheduler - ERROR - Task lambda-b44e325b9f72602b0463700108222ec4 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:53,262 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54413' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-82fffdeaf8077b3a1c93ce9b2e470e39'} (stimulus_id='handle-worker-cleanup-1752124373.2608845')\n",
      "2025-07-10 14:12:53,266 - distributed.scheduler - ERROR - Task lambda-a52fbe142a4b2db31ba628ca131d5993 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:53,268 - distributed.scheduler - ERROR - Task lambda-18ab788a60424146b05cbea21eeb5ce6 marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:53,271 - distributed.scheduler - ERROR - Task lambda-1329ffe237444b3f6092a78adf5edc8b marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:53,273 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54428' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-47217579e3187a294dc169c232fb92aa'} (stimulus_id='handle-worker-cleanup-1752124373.2662575')\n",
      "2025-07-10 14:12:54,119 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54421 (pid=19844) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:54,860 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:54,876 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54421' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-5c8d1072a094f59a0b73bf2f870a5dc7'} (stimulus_id='handle-worker-cleanup-1752124374.8746572')\n",
      "2025-07-10 14:12:54,880 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:55,763 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54415 (pid=4072) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:12:56,150 - distributed.scheduler - ERROR - Task lambda-1afe58544ba33556a794b84b3730bfcb marked as failed because 4 workers died while trying to run it\n",
      "2025-07-10 14:12:56,154 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54415' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-846372667560771c6f5279ab06086018'} (stimulus_id='handle-worker-cleanup-1752124376.149832')\n",
      "2025-07-10 14:12:56,159 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:12:57,775 - distributed.nanny - WARNING - Restarting worker\n",
      "2025-07-10 14:13:01,135 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54440 (pid=14772) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:13:01,671 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54440' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-9611703d826d8d557d223d402cb71dc1', 'lambda-7b4b1e57c21c2d3576a3f09280debe58', 'lambda-be86882405dfc9c93f0b930acc017aba', 'lambda-af813460571bdbb902487059170e19c2'} (stimulus_id='handle-worker-cleanup-1752124381.6707885')\n",
      "2025-07-10 14:13:01,794 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54456 (pid=25196) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:13:02,821 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54456' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-82fffdeaf8077b3a1c93ce9b2e470e39'} (stimulus_id='handle-worker-cleanup-1752124382.8201945')\n",
      "2025-07-10 14:13:03,245 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54462 (pid=22648) exceeded 95% memory budget. Restarting...\n",
      "2025-07-10 14:13:03,364 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54395 (pid=22488) exceeded 95% memory budget. Restarting...\n"
     ]
    },
    {
     "ename": "KilledWorker",
     "evalue": "Attempted to run task 'parse-f21ed0a8a83a60e0703ffc2cd176ce6c' on 4 different workers, but all those workers died while running it. The last worker that attempt to run the task was tcp://127.0.0.1:54094. Inspecting worker logs is often a good next step to diagnose what went wrong. For more information see https://distributed.dask.org/en/stable/killed.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# íŒŒì¼ ê²½ë¡œ\u001b[39;00m\n\u001b[0;32m     11\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../data/í†µí•©_train_ë°ì´í„°.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(file_path)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\storage_formats\\pandas\\query_compiler_caster.py:1144\u001b[0m, in \u001b[0;36mwrap_function_in_argument_caster.<locals>.f_with_argument_casting\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1141\u001b[0m \u001b[38;5;66;03m# We have to set the global Backend correctly for I/O methods like\u001b[39;00m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;66;03m# read_json() to use the correct backend.\u001b[39;00m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(Backend\u001b[38;5;241m=\u001b[39mresult_backend):\n\u001b[1;32m-> 1144\u001b[0m     result \u001b[38;5;241m=\u001b[39m f_to_apply(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[0;32m   1146\u001b[0m     original_castable,\n\u001b[0;32m   1147\u001b[0m     original_qc,\n\u001b[0;32m   1148\u001b[0m     new_castable,\n\u001b[0;32m   1149\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m inplace_update_trackers:\n\u001b[0;32m   1150\u001b[0m     new_qc \u001b[38;5;241m=\u001b[39m new_castable\u001b[38;5;241m.\u001b[39m_get_query_compiler()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\utils.py:631\u001b[0m, in \u001b[0;36mexpanduser_path_arg.<locals>.decorator.<locals>.wrapped\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(patharg, Path):\n\u001b[0;32m    630\u001b[0m         params\u001b[38;5;241m.\u001b[39marguments[argname] \u001b[38;5;241m=\u001b[39m patharg\u001b[38;5;241m.\u001b[39mexpanduser()\n\u001b[1;32m--> 631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\pandas\\io.py:335\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_default:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument is not supported for the fastparquet engine\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    332\u001b[0m     )\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModinObjects\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m--> 335\u001b[0m     query_compiler\u001b[38;5;241m=\u001b[39mFactoryDispatcher\u001b[38;5;241m.\u001b[39mread_parquet(\n\u001b[0;32m    336\u001b[0m         path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m    337\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    338\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m    339\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    340\u001b[0m         use_nullable_dtypes\u001b[38;5;241m=\u001b[39muse_nullable_dtypes,\n\u001b[0;32m    341\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    342\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m    343\u001b[0m         filters\u001b[38;5;241m=\u001b[39mfilters,\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    345\u001b[0m     )\n\u001b[0;32m    346\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dispatching\\factories\\dispatcher.py:246\u001b[0m, in \u001b[0;36mFactoryDispatcher.read_parquet\u001b[1;34m(cls, **kwargs)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;129m@_inherit_docstrings\u001b[39m(factories\u001b[38;5;241m.\u001b[39mBaseFactory\u001b[38;5;241m.\u001b[39m_read_parquet)\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_factory()\u001b[38;5;241m.\u001b[39m_read_parquet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dispatching\\factories\\factories.py:258\u001b[0m, in \u001b[0;36mBaseFactory._read_parquet\u001b[1;34m(cls, **kwargs)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m    252\u001b[0m     _doc_io_method_template,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m )\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_parquet\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mio_cls\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\io\\file_dispatcher.py:159\u001b[0m, in \u001b[0;36mFileDispatcher.read\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03mRead data according passed `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mpostprocessing work on the resulting query_compiler object.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     query_compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_read(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ModinAssumptionError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    161\u001b[0m     param_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfname\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\io\\column_stores\\parquet_dispatcher.py:907\u001b[0m, in \u001b[0;36mParquetDispatcher._read\u001b[1;34m(cls, path, engine, columns, use_nullable_dtypes, dtype_backend, **kwargs)\u001b[0m\n\u001b[0;32m    900\u001b[0m column_names \u001b[38;5;241m=\u001b[39m columns \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;28;01melse\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    901\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    902\u001b[0m     c\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m column_names\n\u001b[0;32m    904\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m index_columns \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mindex_regex\u001b[38;5;241m.\u001b[39mmatch(c)\n\u001b[0;32m    905\u001b[0m ]\n\u001b[1;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_query_compiler(\n\u001b[0;32m    908\u001b[0m     dataset, columns, index_columns, dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    909\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\io\\column_stores\\parquet_dispatcher.py:775\u001b[0m, in \u001b[0;36mParquetDispatcher.build_query_compiler\u001b[1;34m(cls, dataset, columns, index_columns, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m remote_parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_partition(partition_ids, column_widths)\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(partition_ids) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     row_lengths \u001b[38;5;241m=\u001b[39m [part\u001b[38;5;241m.\u001b[39mlength() \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m remote_parts\u001b[38;5;241m.\u001b[39mT[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    777\u001b[0m     row_lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\logging\\logger_decorator.py:149\u001b[0m, in \u001b[0;36menable_logging.<locals>.decorator.<locals>.run_and_log\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m start_time \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LogMode\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 149\u001b[0m     result \u001b[38;5;241m=\u001b[39m obj(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    150\u001b[0m     emit_metric(metric_name, perf_counter() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dask\\implementations\\pandas_on_dask\\partitioning\\partition.py:272\u001b[0m, in \u001b[0;36mPandasOnDaskDataframePartition.length\u001b[1;34m(self, materialize)\u001b[0m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39m_data\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache, Future) \u001b[38;5;129;01mand\u001b[39;00m materialize:\n\u001b[1;32m--> 272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecution_wrapper\u001b[38;5;241m.\u001b[39mmaterialize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_length_cache\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\modin\\core\\execution\\dask\\common\\engine_wrapper.py:160\u001b[0m, in \u001b[0;36mDaskWrapper.materialize\u001b[1;34m(cls, future)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mMaterialize data matching `future` object.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m    An object(s) from the distributed memory.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m client \u001b[38;5;241m=\u001b[39m get_dask_client()\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m client\u001b[38;5;241m.\u001b[39mgather(future)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\distributed\\client.py:2553\u001b[0m, in \u001b[0;36mClient.gather\u001b[1;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[0;32m   2550\u001b[0m     local_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2552\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m-> 2553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msync(\n\u001b[0;32m   2554\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gather,\n\u001b[0;32m   2555\u001b[0m         futures,\n\u001b[0;32m   2556\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   2557\u001b[0m         direct\u001b[38;5;241m=\u001b[39mdirect,\n\u001b[0;32m   2558\u001b[0m         local_worker\u001b[38;5;241m=\u001b[39mlocal_worker,\n\u001b[0;32m   2559\u001b[0m         asynchronous\u001b[38;5;241m=\u001b[39masynchronous,\n\u001b[0;32m   2560\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\distributed\\client.py:2414\u001b[0m, in \u001b[0;36mClient._gather\u001b[1;34m(self, futures, errors, direct, local_worker)\u001b[0m\n\u001b[0;32m   2412\u001b[0m     exception \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mexception\n\u001b[0;32m   2413\u001b[0m     traceback \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mtraceback\n\u001b[1;32m-> 2414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\u001b[38;5;241m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m   2415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2416\u001b[0m     bad_keys\u001b[38;5;241m.\u001b[39madd(key)\n",
      "\u001b[1;31mKilledWorker\u001b[0m: Attempted to run task 'parse-f21ed0a8a83a60e0703ffc2cd176ce6c' on 4 different workers, but all those workers died while running it. The last worker that attempt to run the task was tcp://127.0.0.1:54094. Inspecting worker logs is often a good next step to diagnose what went wrong. For more information see https://distributed.dask.org/en/stable/killed.html."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 14:13:05,057 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54462' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'parse-5c8d1072a094f59a0b73bf2f870a5dc7'} (stimulus_id='handle-worker-cleanup-1752124385.056405')\n",
      "2025-07-10 14:13:05,064 - distributed.scheduler - WARNING - Removing worker 'tcp://127.0.0.1:54395' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {'lambda-bbc1b27b64c98b3c9c97a2650baf8e98', 'lambda-5f36c92bf874021df92202d3369baf42', 'lambda-3947224b284d23576fb31e830e213aa4', 'lambda-23aad8b835b7b772ddf567f7880413b4', 'lambda-d07a7b46d197e6ccc064770b29af67a9', 'lambda-cf61cabc2a40762108f101346a3d1ed7', 'lambda-6d230cb99c75e91d49852221d3e6b6a9', 'lambda-284c0114ef9b23b01851301e8613ed0f', 'lambda-8b51a00ed557f244acbd662fd178f37e', 'lambda-98fd10a58ba1722b3e4b849498bf69bc', 'parse-9f3fa5e57bee07e83e19da82dedd87bb', 'parse-4a2772953aa0b63b6ce9337f14548e8c', 'parse-7128c5acd13b5041846e91cb149c8f86', 'lambda-469ca839151bd1fd5893c86c27648cde'} (stimulus_id='handle-worker-cleanup-1752124385.0636818')\n",
      "2025-07-10 14:13:05,287 - distributed.nanny.memory - WARNING - Worker tcp://127.0.0.1:54448 (pid=6836) exceeded 95% memory budget. Restarting...\n"
     ]
    }
   ],
   "source": [
    "# Modin ë²¡ì—”ë“œë¥¼ rayë¡œ ê°•ì œ ì„¤ì •\n",
    "\n",
    "\n",
    "# ì´í›„ Modin ì½”ë“œ ì‹¤í–‰\n",
    "import modin.pandas as pd\n",
    "df = pd.DataFrame({\"a\": [1,2,3]})\n",
    "print(df)\n",
    "\n",
    "\n",
    "# íŒŒì¼ ê²½ë¡œ\n",
    "file_path = \"../../../data/í†µí•©_train_ë°ì´í„°.parquet\"\n",
    "df = pd.read_parquet(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3904bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(selected_cols))         \n",
    "print(type(selected_cols[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9337062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_categorical_columns(df, verbose=True):\n",
    "    \"\"\"\n",
    "    ë¯¸ë¦¬ ì •ì˜ëœ ë§¤í•‘ ê¸°ì¤€ì— ë”°ë¼ ë²”ì£¼í˜• ì»¬ëŸ¼ë“¤ì„ ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    ì²˜ë¦¬ ì»¬ëŸ¼: ê±°ì£¼ì‹œë„ëª…, ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M, í•œë„ì¦ì•¡íšŸìˆ˜_R12M, ì´ìš©ê¸ˆì•¡ëŒ€,\n",
    "              í• ì¸ê±´ìˆ˜_R3M, í• ì¸ê±´ìˆ˜_B0M, ë°©ë¬¸íšŸìˆ˜_PC_R6M, ë°©ë¬¸íšŸìˆ˜_ì•±_R6M, ë°©ë¬¸ì¼ìˆ˜_PC_R6M\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. ê±°ì£¼ì‹œë„ëª… â†’ ìˆ˜ë„ê¶Œ ì—¬ë¶€\n",
    "    capital_area = ['ì„œìš¸íŠ¹ë³„ì‹œ', 'ê²½ê¸°ë„', 'ì¸ì²œê´‘ì—­ì‹œ']\n",
    "    if 'ê±°ì£¼ì‹œë„ëª…' in df.columns:\n",
    "        df['ê±°ì£¼ì‹œë„_ìˆ˜ë„ê¶Œì—¬ë¶€'] = df['ê±°ì£¼ì‹œë„ëª…'].apply(lambda x: 1 if x in capital_area else 0)\n",
    "        df.drop(columns=['ê±°ì£¼ì‹œë„ëª…'], inplace=True)\n",
    "        if verbose: print(\"[ê±°ì£¼ì‹œë„ëª…] â†’ ìˆ˜ë„ê¶Œ ì—¬ë¶€ ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 2. ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M\n",
    "    mapping = {\"0ê°œ\": 0, \"1ê°œì´ìƒ\": 1}\n",
    "    if 'ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M' in df.columns:\n",
    "        df['ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M'] = df['ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M'].map(mapping).astype(int)\n",
    "        if verbose: print(\"[ì—°íšŒë¹„ë°œìƒì¹´ë“œìˆ˜_B0M] ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 3. í•œë„ì¦ì•¡íšŸìˆ˜_R12M\n",
    "    mapping = {\"0íšŒ\": 0, \"1íšŒì´ìƒ\": 1}\n",
    "    if 'í•œë„ì¦ì•¡íšŸìˆ˜_R12M' in df.columns:\n",
    "        df['í•œë„ì¦ì•¡íšŸìˆ˜_R12M'] = df['í•œë„ì¦ì•¡íšŸìˆ˜_R12M'].map(mapping).astype(int)\n",
    "        if verbose: print(\"[í•œë„ì¦ì•¡íšŸìˆ˜_R12M] ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 4. ì´ìš©ê¸ˆì•¡ëŒ€ (ì¤‘ê°„ê°’ ê¸°ì¤€: ë§Œì› ë‹¨ìœ„)\n",
    "    mapping = {\n",
    "        \"09.ë¯¸ì‚¬ìš©\": 0,\n",
    "        \"05.10ë§Œì›-\": 5,\n",
    "        \"04.10ë§Œì›+\": 20,\n",
    "        \"03.30ë§Œì›+\": 40,\n",
    "        \"02.50ë§Œì›+\": 75,\n",
    "        \"01.100ë§Œì›+\": 150\n",
    "    }\n",
    "    if 'ì´ìš©ê¸ˆì•¡ëŒ€' in df.columns:\n",
    "        df['ì´ìš©ê¸ˆì•¡ëŒ€'] = df['ì´ìš©ê¸ˆì•¡ëŒ€'].map(mapping)\n",
    "        if verbose: print(\"[ì´ìš©ê¸ˆì•¡ëŒ€] ì¤‘ê°„ê°’ ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 5. í• ì¸ê±´ìˆ˜ ì¸ì½”ë”©\n",
    "    discount_map = {\n",
    "        \"1íšŒ ì´ìƒ\": 1,\n",
    "        \"10íšŒ ì´ìƒ\": 10,\n",
    "        \"20íšŒ ì´ìƒ\": 20,\n",
    "        \"30íšŒ ì´ìƒ\": 30,\n",
    "        \"40íšŒ ì´ìƒ\": 40\n",
    "    }\n",
    "    for col in ['í• ì¸ê±´ìˆ˜_R3M', 'í• ì¸ê±´ìˆ˜_B0M']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(discount_map).astype(int)\n",
    "            if verbose: print(f\"[{col}] ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    # 6. ë°©ë¬¸íšŸìˆ˜ ë° ë°©ë¬¸ì¼ìˆ˜ ì¸ì½”ë”©\n",
    "    visit_map = {\n",
    "        \"1íšŒ ì´ìƒ\": 1,\n",
    "        \"10íšŒ ì´ìƒ\": 10,\n",
    "        \"20íšŒ ì´ìƒ\": 20,\n",
    "        \"30íšŒ ì´ìƒ\": 30,\n",
    "        \"40íšŒ ì´ìƒ\": 40,\n",
    "        \"50íšŒ ì´ìƒ\": 50,\n",
    "        \"60íšŒ ì´ìƒ\": 60,\n",
    "        \"70íšŒ ì´ìƒ\": 70,\n",
    "        \"80íšŒ ì´ìƒ\": 80\n",
    "    }\n",
    "\n",
    "    visit_cols = ['ë°©ë¬¸íšŸìˆ˜_PC_R6M', 'ë°©ë¬¸íšŸìˆ˜_ì•±_R6M', 'ë°©ë¬¸ì¼ìˆ˜_PC_R6M']\n",
    "    for col in visit_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].map(visit_map).astype(int)\n",
    "            if verbose: print(f\"[{col}] ì¸ì½”ë”© ì™„ë£Œ\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c972e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import modin.pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "df = pd.read_parquet(\"../../../data/í†µí•©_train_ë°ì´í„°.parquet\")\n",
    "\n",
    "# 2. í”¼ì²˜ ë° íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "X = df[pca_cols].copy() \n",
    "y = df[\"Segment\"]\n",
    "\n",
    "X = X.loc[:, ~X.columns.duplicated()] #ì¤‘ë³µì œê±°\n",
    "\n",
    "# 3. ë²”ì£¼í˜• ì¸ì½”ë”©\n",
    "df = map_categorical_columns(df)\n",
    "cat_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "# 4. ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "X = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(X), columns=X.columns)\n",
    "\n",
    "# ìŠ¤ì¼€ì¼ë§ (DataFrame í˜•íƒœ ìœ ì§€)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# ë¼ë²¨ì¸ì½”ë”©\n",
    "le_y = LabelEncoder()\n",
    "y_encoded = le_y.fit_transform(y)\n",
    "\n",
    "# 6. train-validation ë¶„í• \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n",
    "\n",
    "# CPU ëª¨ë¸ ì‚¬ìš©\n",
    "xgb_model = XGBClassifier(\n",
    "    tree_method='hist',         # GPU ëŒ€ì‹  CPU ì „ìš© ížˆìŠ¤í† ê·¸ëž¨ ê¸°ë°˜\n",
    "    predictor='auto',           # ìžë™ ì„¤ì • (CPUì— ë§žê²Œ)\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# 8. í•™ìŠµ\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# 9. ì˜ˆì¸¡ ë° í‰ê°€\n",
    "y_pred = xgb_model.predict(X_val)\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b20f2-6c05-4a34-b874-49ce16024364",
   "metadata": {},
   "source": [
    "### ì „í™˜ í›„ë³´êµ° ëŒ€ìƒì´ ë˜ëŠ” í”¼ì²˜ íƒìƒ‰\n",
    "- ì˜ˆì¸¡ í™•ë¥ ì´ 0.6 ì´ìƒ ë˜ëŠ” í”¼ì²˜ë¥¼ ì„ íƒí•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6935afb-cb76-4eee-a396-15d09c3005a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import modin.pandas as pd\n",
    "\n",
    "# 10. ì˜ˆì¸¡ í™•ë¥  ê³„ì‚°\n",
    "y_proba = xgb_model.predict_proba(X_val)  # í´ëž˜ìŠ¤ë³„ í™•ë¥  ë°˜í™˜\n",
    "\n",
    "# 11. ê°€ìž¥ ë†’ì€ í™•ë¥ ì˜ í´ëž˜ìŠ¤ ì„ íƒ\n",
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "\n",
    "# 12. í™•ë¥ ì´ 0.6 ì´ìƒì¸ ê³ ê°ë§Œ ì¶”ì¶œ\n",
    "threshold = 0.6\n",
    "high_confidence_mask = np.max(y_proba, axis=1) >= threshold\n",
    "\n",
    "# 13. ê²°ê³¼ ì •ë¦¬\n",
    "result_df = X_val.copy()\n",
    "result_df['real_segment'] = le_y.inverse_transform(y_val)\n",
    "result_df['predicted_segment'] = le_y.inverse_transform(y_pred)\n",
    "result_df['predicted_prob'] = np.max(y_proba, axis=1)\n",
    "\n",
    "# 14. í™•ë¥ ì´ 0.6 ì´ìƒì¸ ì „í™˜ í›„ë³´êµ°ë§Œ ì¶”ì¶œ\n",
    "candidate_df = result_df[high_confidence_mask]\n",
    "\n",
    "# 15. ìƒìœ„ 10ê°œ ë¯¸ë¦¬ë³´ê¸°\n",
    "print(\"âœ… í™•ë¥  0.6 ì´ìƒì¸ ì „í™˜ í›„ë³´êµ°:\")\n",
    "print(candidate_df[['real_segment', 'predicted_segment', 'predicted_prob']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ac489-d2b0-4df1-9d55-49cdd7e5dd3f",
   "metadata": {},
   "source": [
    "### ì „í™˜ ê²½ê³„ì„ ì— ìžˆëŠ” ê³ ê°\n",
    "- 0.5 ~ 0.74 ì‚¬ì´ì— ìžˆëŠ” ê³ ê°ì„ ì „í™˜ í›„ë³´êµ°ìœ¼ë¡œ ì§€ì •í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76ad851-59b9-44b6-9ff0-0c2c1f0e2a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ í™•ë¥ ì´ 0.5 ~ 0.74 ì‚¬ì´ì´ë©´ì„œ, ì‹¤ì œì™€ ì˜ˆì¸¡ì´ ë‹¤ë¥¸ ê²½ìš°ë§Œ!\n",
    "unstable_candidates = result_df[\n",
    "    (result_df['predicted_prob'] >= 0.5) &\n",
    "    (result_df['predicted_prob'] <= 0.74) &\n",
    "    (result_df['real_segment'] != result_df['predicted_segment'])\n",
    "]\n",
    "\n",
    "print(unstable_candidates[['real_segment', 'predicted_segment', 'predicted_prob']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d45538-a49d-4726-a2e6-a3ab47ffa17d",
   "metadata": {},
   "source": [
    "### ì—†ë‹¤ë‹ˆ??\n",
    "\n",
    "#### í˜„ìž¬ ì¡°ê±´\n",
    "- ì˜ˆì¸¡ í™•ë¥ ì´ 0.5 ì´ìƒ 0.74 ì´í•˜ì¸ ì‚¬ëžŒì´ë©´ì„œ\n",
    "- ì‹¤ì œ ì„¸ê·¸ë¨¼íŠ¸ëž‘ ì˜ˆì¸¡ ì„¸ê·¸ë¨¼íŠ¸ê°€ ë‹¤ë¥¸ ì‚¬ëžŒ\n",
    "\n",
    "ì¦‰!! ì´ ë‘ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ëŠ” ì‚¬ëžŒì´ ì—†ë‹¤ëŠ” ëœ»\n",
    "\n",
    "## ì›ì¸ì€?\n",
    "### âœ… ì™œ ì—†ì„ ìˆ˜ë„ ìžˆëƒ?\n",
    "#### ëª¨ë¸ì´ ë„ˆë¬´ í™•ì‹ í•˜ê³  ìžˆì–´ì„œ\n",
    "â†’ ëŒ€ë¶€ë¶„ì˜ ì˜ˆì¸¡ í™•ë¥ ì´ 0.9 ì´ìƒì´ì•¼ (ì‹¤ì œë¡œ ì¶œë ¥ëœ ê±° ë³´ë©´ ê±°ì˜ ë‹¤ 0.999...)\n",
    "\n",
    "#### ë°ì´í„°ê°€ ê· í˜• ìž¡í˜€ ìžˆì–´ì„œ ì˜ˆì¸¡ì´ ë‹¨ë‹¨í•  ìˆ˜ ìžˆìŒ\n",
    "â†’ ê·¸ëž˜ì„œ ì „í™˜ â€œê²½ê³„ì„ â€ì— ì• ë§¤í•˜ê²Œ ê±¸ì¹œ ì‚¬ëžŒì´ ì•ˆ ë³´ì´ëŠ” ê±°ì•¼\n",
    "\n",
    "#### ë°ì´í„°ì…‹ ì‚¬ì´ì¦ˆê°€ ìž‘ê±°ë‚˜ testì…‹ì— ê·¸ëŸ° ì¼€ì´ìŠ¤ê°€ ì—†ëŠ” ê²ƒì¼ ìˆ˜ë„ ìžˆìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447a0b9-cdd9-4677-af46-260626e03fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™•ë¥ ì„ ë” ë„“ê²Œ: 0.4 ~ 0.8 ì‚¬ì´\n",
    "unstable_candidates = result_df[\n",
    "    (result_df['predicted_prob'] >= 0.4) &\n",
    "    (result_df['predicted_prob'] <= 0.8) &\n",
    "    (result_df['real_segment'] != result_df['predicted_segment'])\n",
    "]\n",
    "\n",
    "print(unstable_candidates[['real_segment', 'predicted_segment', 'predicted_prob']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90476cf5-4e11-4928-8af5-d9f0d1df8557",
   "metadata": {},
   "source": [
    "### ì‹¤ì œ í•™ìŠµëœ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì •í™•ë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e151197-e7f3-49fd-9dc4-8e0ab5ae70ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ë³¸\n",
    "import modin.pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ê²½ê³  ëœ¨ì§€ ì•Šê²Œ ì„¤ì •\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ê·¸ëž˜í”„ ì„¤ì •\n",
    "sns.set()\n",
    "\n",
    "# ê·¸ëž˜í”„ ê¸°ë³¸ ì„¤ì •\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import missingno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bfc1ec-e601-4d43-968c-b08dfbf12108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(result_df['predicted_prob'], bins=30, kde=True)\n",
    "plt.axvline(0.6, color='red', linestyle='--', label='0.6 threshold')\n",
    "plt.title(\"ðŸ“Š ì „ì²´ ì˜ˆì¸¡ í™•ë¥  ë¶„í¬\")\n",
    "plt.xlabel(\"Predicted Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9952fbfc-332b-4e77-a5b4-f801d2cedb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_proba[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99b4b25-128d-4693-b72c-847c75e55bff",
   "metadata": {},
   "source": [
    "## ðŸ” ì˜ˆì¸¡ í™•ë¥  ë¶„ì„ ê²°ê³¼ ì •ë¦¬\n",
    "\n",
    "### âœ… ì˜ˆì¸¡ í™•ë¥  ë¶„í¬ í•´ì„\n",
    "- ëŒ€ë¶€ë¶„ì˜ ì˜ˆì¸¡ í™•ë¥ ì´ `0.999 ì´ìƒ`ì— ëª°ë ¤ ìžˆìŒ\n",
    "- ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ **ê±°ì˜ 100% í™•ì‹ ì„ ê°€ì§€ê³  ìžˆìŒ**\n",
    "- ë”°ë¼ì„œ, ì „í™˜ ê°€ëŠ¥ì„±ì´ ìžˆëŠ” **ê²½ê³„ì„  ê³ ê° (ì˜ˆ: 0.5 ~ 0.74)** ì€ ê±°ì˜ ì—†ìŒ\n",
    "\n",
    "---\n",
    "\n",
    "### âš ï¸ ë¬¸ì œì  ìš”ì•½\n",
    "\n",
    "| í•­ëª© | ì„¤ëª… |\n",
    "|------|------|\n",
    "| ê³¼í™•ì‹  (Overconfidence) | ëª¨ë¸ì´ ëª¨ë“  ì˜ˆì¸¡ì— ëŒ€í•´ ë„ˆë¬´ í™•ì‹ í•¨ (í™•ë¥  ë¶„í¬ê°€ í•œìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨) |\n",
    "| ì „í™˜ í›„ë³´ ë¶€ì¡± | `real_segment â‰  predicted_segment` ì´ë©´ì„œ `í™•ë¥ ì´ ì• ë§¤í•œ ê³ ê°`ì´ ê±°ì˜ ì—†ìŒ |\n",
    "| í•´ì„ ì–´ë ¤ì›€ | SHAP ì—†ì´ ì˜ˆì¸¡ ê²°ê³¼ë§Œìœ¼ë¡œëŠ” KPI ë¶„ì„ì´ë‚˜ ì „í™˜ ì¸ì‚¬ì´íŠ¸ ë„ì¶œì´ ì–´ë ¤ì›€ |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ ì›ì¸ ì¶”ì •\n",
    "\n",
    "1. **ê³¼ì í•©**: validation dataê¹Œì§€ ì™¸ìš´ ë“¯í•œ ëª¨ë¸ ë™ìž‘\n",
    "2. **í´ëž˜ìŠ¤ ë¶ˆê· í˜•**: íŠ¹ì • ì„¸ê·¸ë¨¼íŠ¸ê°€ ë§Žì•„ì„œ ê·¸ìª½ìœ¼ë¡œ ì ë¦¼\n",
    "3. **ê°•í•œ í”¼ì²˜**: ì¼ë¶€ í”¼ì²˜ê°€ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ê±°ì˜ ê²°ì •í•  ì •ë„ë¡œ ê°•ë ¥\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ\n",
    "\n",
    "- SHAP ë¶„ì„ìœ¼ë¡œ ëª¨ë¸ì´ **ì™œ í™•ì‹ í•˜ê³  ìžˆëŠ”ì§€** í”¼ì²˜ ê¸°ë°˜ìœ¼ë¡œ í•´ì„\n",
    "- ë‹¤ë¥¸ ëª¨ë¸(Logistic, LightGBM ë“±)ê³¼ ë¹„êµ\n",
    "- ì˜ˆì¸¡ ë°ì´í„°ì…‹ì„ ì§„ì§œ ìš´ì˜ ê³ ê° ë°ì´í„°ë¡œ êµì²´í•´ë³´ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099fee94-b454-4b72-af53-7c5ad1a60805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# 1. TreeExplainer ì •ì˜\n",
    "explainer = shap.Explainer(xgb_model)\n",
    "\n",
    "# 2. validation ë°ì´í„°ì— ëŒ€í•œ shap ê°’ ê³„ì‚°\n",
    "shap_values = explainer(X_val)\n",
    "\n",
    "# 3. SHAP summary plot (feature ì¤‘ìš”ë„ ì „ì²´ ì‹œê°í™”)\n",
    "shap.summary_plot(shap_values, X_val, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34b9486-a6c3-4e31-be86-10ee5bd5bfc1",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ SHAP ë¶„ì„ ê¸°ë°˜ KPI í›„ë³´ ì§€í‘œ\n",
    "\n",
    "1. **ì •ìƒì²­êµ¬ì›ê¸ˆ_B5M**  \n",
    "   - ìµœê·¼ 5ê°œì›” ë™ì•ˆ ì²­êµ¬ëœ ì •ìƒ ì›ê¸ˆ ì´ì•¡  \n",
    "   - ê³ ê°ì˜ ìƒí™˜ ê·œëª¨ ë˜ëŠ” ë¶€ì±„ ìˆ˜ì¤€ì„ ë³´ì—¬ì£¼ëŠ” ì£¼ìš” ì§€í‘œ\n",
    "\n",
    "2. **ì´ìš©ê¸ˆì•¡_R3M_ì‹ ìš©ì²´í¬**  \n",
    "   - ìµœê·¼ 3ê°œì›”ê°„ ì‹ ìš© ë° ì²´í¬ì¹´ë“œ ì´ìš©ì•¡  \n",
    "   - ì¹´ë“œ ì‚¬ìš© íŒ¨í„´ê³¼ ì†Œë¹„ ì„±í–¥ ë°˜ì˜\n",
    "\n",
    "3. **ì²­êµ¬ê¸ˆì•¡_R6M**  \n",
    "   - ìµœê·¼ 6ê°œì›” ëˆ„ì  ì²­êµ¬ ê¸ˆì•¡  \n",
    "   - ê³ ì•¡ ì²­êµ¬ ê³ ê° â†’ ìƒí–¥ ê°€ëŠ¥ì„± íŒë‹¨ ê°€ëŠ¥\n",
    "\n",
    "4. **ì¹´ë“œë¡ ì´ìš©ê¸ˆì•¡_ëˆ„ì  / í‰ìž”_í• ë¶€_3M** ë“±ë„ ë’¤ë”°ë¼ ë“±ìž¥  \n",
    "   - ë¦¬ë³¼ë¹™Â·í• ë¶€ ìŠµê´€ì€ ë¦¬ìŠ¤í¬ ìš”ì¸ or ë“±ê¸‰ ìœ ì§€ ìš”ì¸ìœ¼ë¡œ ìž‘ìš© ê°€ëŠ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e02496-db1d-4587-bc64-2acf17ae47e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
