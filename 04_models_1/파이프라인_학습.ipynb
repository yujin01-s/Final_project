{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d714cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import platform\n",
    "\n",
    "# ì‹œìŠ¤í…œì´ Windowsì¼ ê²½ìš°\n",
    "if platform.system() == 'Windows':\n",
    "    plt.rc('font', family='Pretendard')\n",
    "# macOSì¼ ê²½ìš° ì˜ˆì‹œ:\n",
    "elif platform.system() == 'Darwin':\n",
    "    plt.rc('font', family='AppleGothic')\n",
    "\n",
    "# ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f457865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.\n",
      "âœ… ë²”ì£¼í˜• ì¸ì½”ë”© ì™„ë£Œ\n",
      "ğŸ“Œ ê°€ê³µëœ ì»¬ëŸ¼ ìˆ˜: 30\n"
     ]
    }
   ],
   "source": [
    "from modules.data_loader import load_and_process\n",
    "from modules.feature_selector import stage_feature_map\n",
    "\n",
    "file_path = \"../data/í†µí•©_train_ë°ì´í„°.parquet\"\n",
    "test_path = \"../data/í†µí•©_test_ë°ì´í„°.parquet\"\n",
    "\n",
    "stage_name = \"ab\" # <- ë³€ê²½í•´ì„œ ì‚¬ìš©\n",
    "save_path = \"./models\"\n",
    "\n",
    "if stage_name!=\"all\":\n",
    "    df_train, used_cols = load_and_process(file_path=file_path, stage=stage_name)\n",
    "    print(\"ğŸ“Œ ê°€ê³µëœ ì»¬ëŸ¼ ìˆ˜:\", len(used_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743deb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” AB ì„¸ê·¸ë¨¼íŠ¸ ëª¨ë¸ë§ ì‹œì‘\n",
      "ğŸ“Œ A/B ìƒ˜í”Œ ìˆ˜: 1116\n",
      "âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ: (892, 30) (224, 30)\n",
      "âœ… SMOTE ì ìš© ì™„ë£Œ\n",
      "  â†’ Before: 892 samples\n",
      "  â†’ After:  1554 samples (class balanced)\n",
      "ğŸ§  XGBoost ëª¨ë¸ ì •ì˜ ì™„ë£Œ\n",
      "[00:44:52] WARNING: D:\\bld\\xgboost-split_1700181085428\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"device\" } are not used.\n",
      "\n",
      "[00:44:53] WARNING: D:\\bld\\xgboost-split_1700181085428\\work\\src\\learner.cc:767: \n",
      "Parameters: { \"device\" } are not used.\n",
      "\n",
      "âœ… [XGB_AB]\n",
      "ğŸ“Š ì„±ëŠ¥ í‰ê°€:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       195\n",
      "           1       0.66      0.79      0.72        29\n",
      "\n",
      "    accuracy                           0.92       224\n",
      "   macro avg       0.81      0.87      0.84       224\n",
      "weighted avg       0.93      0.92      0.92       224\n",
      "\n",
      "F1 Macro : 0.8359375\n",
      "F1 Micro : 0.9196428571428571\n",
      "F1 Weighted : 0.9227818080357143\n",
      "\n",
      "ğŸŒŸ ìµœì  Threshold: 0.786 (F1 Score: 0.7857)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[00:44:53] D:\\bld\\xgboost-split_1700181085428\\work\\dmlc-core\\src\\io\\local_filesys.cc:209: Check failed: allow_null:  LocalFileSystem::Open \"./models\": Permission denied",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# âœ… ABë§Œ í•™ìŠµ\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stage_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mab\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 18\u001b[0m     result \u001b[38;5;241m=\u001b[39m run_AB_modeling(df_train, used_cols, save_path)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# âœ… Eë§Œ í•™ìŠµ\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stage_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\somee\\Documents\\GitHub\\Final_project\\04_models_1\\modules\\model_AB.py:56\u001b[0m, in \u001b[0;36mrun_AB_modeling\u001b[1;34m(df, used_cols, save_path)\u001b[0m\n\u001b[0;32m     53\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(save_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     55\u001b[0m booster \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_booster()\n\u001b[1;32m---> 56\u001b[0m booster\u001b[38;5;241m.\u001b[39msave_model(save_path)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_ab,\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m: ab_feat,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: best_f1,\n\u001b[0;32m     71\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\somee\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2389\u001b[0m, in \u001b[0;36mBooster.save_model\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m   2387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):  \u001b[38;5;66;03m# assume file name\u001b[39;00m\n\u001b[0;32m   2388\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname))\n\u001b[1;32m-> 2389\u001b[0m     _check_call(_LIB\u001b[38;5;241m.\u001b[39mXGBoosterSaveModel(\n\u001b[0;32m   2390\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, c_str(fname)))\n\u001b[0;32m   2391\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfname must be a string or os PathLike\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\somee\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:279\u001b[0m, in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \n\u001b[0;32m    270\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [00:44:53] D:\\bld\\xgboost-split_1700181085428\\work\\dmlc-core\\src\\io\\local_filesys.cc:209: Check failed: allow_null:  LocalFileSystem::Open \"./models\": Permission denied"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "from modules.model_AB import run_AB_modeling\n",
    "from modules.model_CD import run_cd_modeling\n",
    "from modules.model_E import run_E_modeling\n",
    "from modules.model_baseline import run_baseline_modeling\n",
    "from modules.model_utils import combine_segment_predictions\n",
    "from modules.feature_selector import pca_cols, ab_feat, cd_baseline, selected_cols\n",
    "from modules.feature_selector import stage_feature_map\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# âœ… CDë§Œ í•™ìŠµ\n",
    "if stage_name == \"cd\":\n",
    "    result = run_cd_modeling(df_train, used_cols, save_path)\n",
    "\n",
    "# âœ… ABë§Œ í•™ìŠµ\n",
    "elif stage_name == \"ab\":\n",
    "    result = run_AB_modeling(df_train, used_cols)\n",
    "\n",
    "# âœ… Eë§Œ í•™ìŠµ\n",
    "elif stage_name == \"e\":\n",
    "    result = run_E_modeling(df_train, used_cols, save_path)\n",
    "\n",
    "# âœ… ë² ì´ìŠ¤ë¼ì¸ í•™ìŠµ\n",
    "elif stage_name in [\"baseline\", \"base\", \"\"]:\n",
    "    from modules.model_baseline import run_baseline_modeling\n",
    "    result = run_baseline_modeling(df_train, used_cols, save_path)\n",
    "\n",
    "# âœ… ëª¨ë“  ëª¨ë¸ì„ ì‹¤í–‰í•˜ê³  test ì˜ˆì¸¡ ë° í†µí•©\n",
    "if stage_name == \"all\":\n",
    "    print(\"ğŸš€ ì „ì²´ ëª¨ë¸ í•™ìŠµ ë° test ì˜ˆì¸¡ ì‹œì‘\")\n",
    "    \n",
    "    # ğŸ”¸ 1. E ëª¨ë¸\n",
    "    e_cols = selected_cols\n",
    "    train_e, e_cols = load_and_process(file_path, stage=\"e\")\n",
    "    print(\"ğŸ“Š [train_e] Segment ë¶„í¬:\\n\", train_e[\"Segment\"].value_counts())\n",
    "\n",
    "    e_result = run_E_modeling(train_e, e_cols, save_path)\n",
    "    e_model = e_result[\"model\"]\n",
    "    e_thresh = e_result[\"threshold\"]\n",
    "\n",
    "    test_e, _ = load_and_process(test_path, stage=\"e\", base_cols=[\"ID\"]) \n",
    "\n",
    "    e_probs = e_model.predict_proba(test_e[e_cols])[:, 1]\n",
    "    e_preds_bin = (e_probs > e_thresh).astype(int)\n",
    "\n",
    "    # ğŸ”¹ e_preds_bin: 1 = 'E', 0 = Others\n",
    "    e_preds = np.full(len(test_e), fill_value=None)  # ìµœì¢… ë ˆì´ë¸” ì €ì¥ìš©\n",
    "\n",
    "    # ğŸ”¸ 2. AB ëª¨ë¸ (E ì œì™¸ + A/B ì˜ˆì¸¡)\n",
    "    ab_mask = (e_preds_bin == 0)\n",
    "    test_ab = test_e.loc[ab_mask].copy()\n",
    "    train_ab, ab_cols = load_and_process(file_path, stage=\"ab\")\n",
    "    ab_result = run_AB_modeling(train_ab, ab_cols, save_path)\n",
    "    ab_model = ab_result[\"model\"]\n",
    "    ab_thresh = ab_result[\"threshold\"]\n",
    "\n",
    "    ab_probs = ab_model.predict_proba(test_ab[ab_cols])[:, 1]\n",
    "    ab_preds_bin = (ab_probs > ab_thresh).astype(int)\n",
    "    ab_mapping = {0: 'A', 1: 'B'}\n",
    "\n",
    "    # ğŸ”¸ 3. CD ëª¨ë¸ (E ì œì™¸ + C/D ì˜ˆì¸¡)\n",
    "    train_cd, cd_cols = load_and_process(file_path, stage=\"cd\")\n",
    "    cd_result = run_cd_modeling(train_cd, cd_cols, save_path)\n",
    "    cd_model = cd_result[\"model\"]\n",
    "    cd_thresh = cd_result[\"threshold\"]\n",
    "\n",
    "    test_cd = test_e.loc[ab_mask].copy()  # CDì™€ ABëŠ” ê°™ì€ ëŒ€ìƒì—ì„œ ê°ˆë¼ì§\n",
    "    cd_probs = cd_model.predict_proba(test_cd[cd_cols])[:, 1]\n",
    "    cd_preds_bin = (cd_probs > cd_thresh).astype(int)\n",
    "    cd_mapping = {0: 'C', 1: 'D'}\n",
    "\n",
    "    # ğŸ”¸ 4. ìµœì¢… ë ˆì´ë¸” í†µí•©\n",
    "    final_preds = []\n",
    "\n",
    "    for i in range(len(test_e)):\n",
    "        if e_preds_bin[i] == 1:\n",
    "            final_preds.append('E')\n",
    "        else:\n",
    "            # AB/CD ë¶„ê¸° ê¸°ì¤€ í•„ìš” (ì˜ˆ: AB/CD ëª¨ë¸ ê¸°ì¤€ ìŠ¤ì½”ì–´ ë¹„êµ or ë³„ ê¸°ì¤€)\n",
    "            # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œë¡œ AB ëª¨ë¸ ìš°ì„  ì ìš© (B vs A)\n",
    "            if i in test_ab.index:\n",
    "                final_preds.append(ab_mapping[ab_preds_bin[test_ab.index.get_loc(i)]])\n",
    "            else:\n",
    "                final_preds.append(cd_mapping[cd_preds_bin[test_cd.index.get_loc(i)]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3f2e51d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotADirectoryError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâ— \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ê²½ë¡œê°€ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹ˆë¼ íŒŒì¼ì…ë‹ˆë‹¤. ì‚­ì œí•˜ê±°ë‚˜ ê²½ë¡œëª…ì„ ë³€ê²½í•˜ì„¸ìš”.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m booster \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_booster()\n\u001b[0;32m      8\u001b[0m booster\u001b[38;5;241m.\u001b[39msave_model(save_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# 9. Boosterë¡œ ì €ì¥ (JSON)\n",
    "import os\n",
    "if os.path.exists(\"./models\") and not os.path.isdir(\"./models\"):\n",
    "    raise NotADirectoryError(\"â— './models' ê²½ë¡œê°€ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹ˆë¼ íŒŒì¼ì…ë‹ˆë‹¤. ì‚­ì œí•˜ê±°ë‚˜ ê²½ë¡œëª…ì„ ë³€ê²½í•˜ì„¸ìš”.\")\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "booster = model.get_booster()\n",
    "booster.save_model(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # ğŸ”¸ 5. ì œì¶œ íŒŒì¼ ì €ì¥\n",
    "submission = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "submission[\"Segment\"] = final_preds\n",
    "submission.to_csv(\"prediction_binary.csv\", index=False)\n",
    "print(\"âœ… submission_final.csv ì €ì¥ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e3a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§ª stage_feature_map keys: dict_keys(['base', 'cd_base', 'cd', 'ab'])\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ§ª stage_feature_map keys:\", stage_feature_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3669256",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbcd019",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"Segment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ê°’ í™•ì¸\n",
    "print(result[\"y_pred\"][:5])\n",
    "\n",
    "# F1 score ì¶œë ¥\n",
    "print(\"ğŸ“Œ ìµœì  F1 Score:\", result[\"f1_score\"])\n",
    "\n",
    "# ëª¨ë¸ í™•ì¸\n",
    "print(\"ëª¨ë¸ êµ¬ì¡°:\")\n",
    "print(result[\"model\"])\n",
    "\n",
    "# SHAP ë¶„ì„ìš©\n",
    "import shap\n",
    "explainer = shap.Explainer(result[\"model\"])\n",
    "shap_values = explainer(result[\"X_val\"])\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.model_utils import get_xgb_model, train_and_evaluate, apply_smote\n",
    "from modules.model_utils import get_model\n",
    "\n",
    "X_resampled, y_resampled = apply_smote(X_train, y_train) # SMOTE ì ìš©, k_neighbors ì¡°ì ˆ ê°€ëŠ¥\n",
    "model = get_xgb_model() # xgb ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸) / íŒŒë¼ë¯¸í„° ì¡°ì ˆ ê°€ëŠ¥\n",
    "\n",
    "#get_modelë¡œ ê°€ì ¸ì˜¤ê¸°ë„ ê°€ëŠ¥\n",
    "model1 = get_model(\"xgb\", {\"max_depth\": 4})\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model = train_and_evaluate(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506ae6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.model_utils import apply_best_threshold\n",
    "\n",
    "best_thresh, best_f1, y_pred = apply_best_threshold(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50fce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.model_utils import save_model_and_results\n",
    "\n",
    "model = get_model(\"xgb\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "save_model_and_results(model, model_name=\"XGB_CD\", save_path=\"./outputs/cd_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°œë³„ëª¨ë¸ ë°˜ë³µì‹¤í–‰\n",
    "from modules.model_utils import get_model\n",
    "from modules.ensemble import run_custom_experiments\n",
    "\n",
    "model_list = [\n",
    "    (\"XGB_d4\", get_model(\"xgb\", {\"max_depth\": 4})),\n",
    "    (\"XGB_d6\", get_model(\"xgb\", {\"max_depth\": 6})),\n",
    "    (\"RF_100\", get_model(\"rf\", {\"n_estimators\": 100})),\n",
    "    (\"LR_C1\", get_model(\"lr\", {\"C\": 1.0}))\n",
    "]\n",
    "#results_df = run_custom_experiments(X_train, y_train, X_val, y_val, model_list) <- ìœ„ ì¡°ì ˆí›„ ì£¼ì„ì§€ìš°ê³  ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a658bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting ì•™ìƒë¸” ì‹¤í–‰\n",
    "from modules.model_utils import get_model\n",
    "from modules.ensemble import run_voting_ensemble\n",
    "\n",
    "models = [\n",
    "    (\"xgb\", get_model(\"xgb\")),\n",
    "    (\"rf\", get_model(\"rf\")),\n",
    "    (\"lgbm\", get_model(\"lgbm\"))\n",
    "]\n",
    "weights = [3, 1, 2]\n",
    "\n",
    "# result = run_voting_ensemble(X_train, y_train, X_val, y_val, model_configs=models, weights=weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking ì•™ìƒë¸” ì‹¤í–‰\n",
    "from modules.model_utils import get_model\n",
    "from modules.ensemble import run_stacking_ensemble\n",
    "\n",
    "base_models = [\n",
    "    (\"lr\", get_model(\"lr\")),\n",
    "    (\"cat\", CatBoostClassifier(verbose=0)),\n",
    "    (\"svm\", SVC(probability=True))\n",
    "]\n",
    "\n",
    "# ë©”íƒ€ ëª¨ë¸ë¡œ XGBoost ì‚¬ìš©\n",
    "#result = run_stacking_ensemble(X_train, y_train, X_val, y_val, base_models, meta_model_name=\"xgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc6d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_CD\n",
    "\n",
    "stage_to_model = {\n",
    "    \"cd\": train_model_CD\n",
    "    #\"ab\": train_model_AB,\n",
    "}\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if stage_name in stage_to_model:\n",
    "    model = stage_to_model[stage_name](df_train, used_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220ebe5c",
   "metadata": {},
   "source": [
    "# í•­ëª©ë³„ í™•ì¸ ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ê°’ í™•ì¸\n",
    "print(result[\"y_pred\"][:5])\n",
    "\n",
    "# F1 score ì¶œë ¥\n",
    "print(\"ğŸ“Œ ìµœì  F1 Score:\", result[\"f1_score\"])\n",
    "\n",
    "# ëª¨ë¸ í™•ì¸\n",
    "print(\"ëª¨ë¸ êµ¬ì¡°:\")\n",
    "print(result[\"model\"])\n",
    "\n",
    "# SHAP ë¶„ì„ìš©\n",
    "import shap\n",
    "explainer = shap.Explainer(result[\"model\"])\n",
    "shap_values = explainer(result[\"X_val\"])\n",
    "shap.plots.beeswarm(shap_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
