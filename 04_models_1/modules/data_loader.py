import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.impute import SimpleImputer
from modules.feature_selector import stage_feature_map

from modules.preprocess_utils import (
    map_categorical_columns,
    encode_categorical_columns
)

def load_and_process(file_path: str,
                     stage: str = None,
                     selected_cols: list = None,
                     base_cols: list = ["ID", "Segment"]):
    """
    íŒŒì¼ì„ ë¶ˆëŸ¬ì˜¤ê³ , stage ë˜ëŠ” selected_cols ê¸°ë°˜ìœ¼ë¡œ ì»¬ëŸ¼ì„ ì¶”ì¶œ + ë²”ì£¼í˜• ì¸ì½”ë”©

    Parameters:
    - file_path (str): .parquet ë˜ëŠ” .csv
    - stage (str): stage_feature_mapì—ì„œ í‚¤ë¥¼ ì°¾ì•„ ì»¬ëŸ¼ ìë™ ë§¤í•‘
    - selected_cols (list): ì§ì ‘ ì§€ì •í•œ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (stageê°€ Noneì¼ ë•Œ ì‚¬ìš©)
    - base_cols (list): í•­ìƒ í¬í•¨í•  ê¸°ì¤€ ì»¬ëŸ¼

    Returns:
    - df_final (pd.DataFrame): base_cols + ê°€ê³µëœ ì»¬ëŸ¼
    - used_columns (list): ê°€ê³µ ëŒ€ìƒ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (base ì œì™¸)
    """

    # íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    if file_path.endswith(".parquet"):
        df = pd.read_parquet(file_path)
    elif file_path.endswith(".csv"):
        df = pd.read_csv(file_path)
    else:
        raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
    print("ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì™„ë£Œ.")

    # âœ… stage ê¸°ë°˜ selected_cols ì„¤ì •
    if stage is not None:
        if stage not in stage_feature_map:
            raise ValueError(f"'{stage}'ëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        selected_cols = stage_feature_map[stage]

    # âœ… base + selected_cols ê¸°ì¤€ í•„í„°ë§
    if selected_cols is not None:
        keep_cols = list(set(base_cols + selected_cols))
        df = df[keep_cols]

    # âœ… ì¤‘ë³µ ì»¬ëŸ¼ ì œê±°
    df = df.loc[:, ~df.columns.duplicated()]

    # âœ… ì‚¬ìš©ì ì •ì˜ ë§¤í•‘
    df = map_categorical_columns(df)

    # âœ… ë‚¨ì€ ë²”ì£¼í˜• ì¸ì½”ë”©
    object_cols = df.select_dtypes(include='object').columns.tolist()
    for col in object_cols:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))
        #print(f"âœ… Label Encoding ì ìš©: {col}")
    print("âœ… ë²”ì£¼í˜• ì¸ì½”ë”© ì™„ë£Œ")
    # ğŸ• ì‚¬ìš©ëœ ì»¬ëŸ¼ ì •ë¦¬
    used_columns = [col for col in df.columns if col not in base_cols]
    df.head(5)
    return df, used_columns


def test_load(path: str, scaler: StandardScaler = None):
    """
    í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© + ì „ì²˜ë¦¬ (íƒ€ê²Ÿ ì—†ìŒ)
    Args:
        path (str): í†µí•©ëœ parquet í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ
        scaler (StandardScaler): trainì—ì„œ ì‚¬ìš©í•œ ìŠ¤ì¼€ì¼ëŸ¬ ê°ì²´

    Returns:
        X_test (DataFrame): ì „ì²˜ë¦¬ëœ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    """
    print(f"ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”© ì¤‘: {path}")
    df = pd.read_parquet(path)

    X = df.copy()
    X = X.loc[:, ~X.columns.duplicated()]

    # ì „ì²˜ë¦¬ ë™ì¼í•˜ê²Œ ì ìš©
    X = map_categorical_columns(X)
    X = encode_categorical_columns(X)

    imputer = SimpleImputer(strategy='mean')
    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

    if scaler:
        X = pd.DataFrame(scaler.transform(X), columns=X.columns)
        print("ğŸ“ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ ì ìš© ì™„ë£Œ")

    print(f"âœ… test_load ì™„ë£Œ: X={X.shape}")
    return X
