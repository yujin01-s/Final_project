# modules/model_cd.py

from modules.feature_selector import baseline_feat
from modules.model_utils import get_xgb_model, get_model, train_and_evaluate, apply_smote, apply_best_threshold, save_model_and_results, apply_oversampling
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import pandas as pd

def run_baseline_modeling(df, used_cols, save_path=None):
    print("ğŸ” ì „ì²´ ì„¸ê·¸ë¨¼íŠ¸ ëª¨ë¸ë§ ì‹œì‘")

    # 1. íŒŒìƒë³€ìˆ˜ ìƒì„±
    #df = generate_base_derived_features(df) 

    # 2. X, y ë¶„ë¦¬
    X = df[baseline_feat]
    y = df["Segment"]

    # 3. ë¼ë²¨ ì¸ì½”ë”©
    le = LabelEncoder()
    y_encoded = le.fit_transform(y)

    # 4. train/val ë¶„ë¦¬
    X_train, X_val, y_train, y_val = train_test_split(X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)
    print("âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:", X_train.shape, X_val.shape)

    # 5. ì˜¤ë²„ìƒ˜í”Œë§ (ì„ íƒì ìœ¼ë¡œ SMOTE ì‚¬ìš©)
    X_train, y_train = apply_oversampling(X_train, y_train)

    # 6. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
    model = get_xgb_model()  # ë˜ëŠ” get_model("xgb", {...})
    model.fit(X_train, y_train)
    train_and_evaluate(model, X_train, y_train, X_val, y_val, model_name="XGB_base")

    # 7. ì˜ˆì¸¡ ë¼ë²¨ ë‹¤ì‹œ ë””ì½”ë”©
    y_pred = le.inverse_transform(y_pred)
    y_val = le.inverse_transform(y_val)

    # 8. ì €ì¥
    if save_path:
        save_model_and_results(model, model_name="XGB_base", save_path=save_path)

    return {
        "df": df,
        "features": baseline_feat,
        "X_train": X_train,
        "X_val": X_val,
        "y_train": y_train,
        "y_val": y_val,
        "y_pred": y_pred,
        "model": model,
        "f1_score": best_f1
    }
